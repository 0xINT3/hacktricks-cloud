# Pentesting Cloud Methodology

<details>

<summary><strong>Lernen Sie AWS-Hacking von Null auf Held mit</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (HackTricks AWS Red Team Expert)</strong></a><strong>!</strong></summary>

Andere M√∂glichkeiten, HackTricks zu unterst√ºtzen:

- Wenn Sie Ihr **Unternehmen in HackTricks beworben sehen m√∂chten** oder **HackTricks in PDF herunterladen m√∂chten**, √ºberpr√ºfen Sie die [**ABONNEMENTPL√ÑNE**](https://github.com/sponsors/carlospolop)!
- Holen Sie sich das [**offizielle PEASS & HackTricks-Merchandise**](https://peass.creator-spring.com)
- Entdecken Sie [**The PEASS Family**](https://opensea.io/collection/the-peass-family), unsere Sammlung exklusiver [**NFTs**](https://opensea.io/collection/the-peass-family)
- **Treten Sie der** üí¨ [**Discord-Gruppe**](https://discord.gg/hRep4RUj7f) oder der [**Telegramm-Gruppe**](https://t.me/peass) bei oder **folgen** Sie uns auf **Twitter** üê¶ [**@hacktricks_live**](https://twitter.com/hacktricks_live)**.**
- **Teilen Sie Ihre Hacking-Tricks, indem Sie PRs an die** [**HackTricks**](https://github.com/carlospolop/hacktricks) und [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) Github-Repositorys senden.

</details>

<figure><img src="../.gitbook/assets/CLOUD-logo-letters.svg" alt=""><figcaption></figcaption></figure>

## Grundmethodik

Jede Cloud hat ihre eigenen Besonderheiten, aber im Allgemeinen gibt es einige **gemeinsame Dinge, die ein Pentester √ºberpr√ºfen sollte**, wenn er eine Cloud-Umgebung testet:

- **Benchmark-Checks**
  - Dies hilft Ihnen, die **Gr√∂√üe der Umgebung** und die **verwendeten Dienste zu verstehen**
  - Es erm√∂glicht Ihnen auch, einige **schnelle Fehlkonfigurationen** zu finden, da die meisten dieser Tests mit **automatisierten Tools** durchgef√ºhrt werden k√∂nnen
- **Dienste Enumeration**
  - Hier werden Sie wahrscheinlich nicht viele weitere Fehlkonfigurationen finden, wenn Sie die Benchmark-Tests korrekt durchgef√ºhrt haben, aber Sie k√∂nnten einige finden, die in den Benchmark-Tests nicht gesucht wurden.
  - Dies erm√∂glicht es Ihnen zu wissen, **was genau in der Cloud-Umgebung verwendet wird**
  - Dies wird in den n√§chsten Schritten sehr hilfreich sein
- **√úberpr√ºfung exponierter Assets**
  - Dies kann im vorherigen Abschnitt durchgef√ºhrt werden. Sie m√ºssen **herausfinden, was potenziell dem Internet ausgesetzt ist** und wie darauf zugegriffen werden kann.
  - Hierbei handelt es sich um **manuell exponierte Infrastruktur** wie Instanzen mit Webseiten oder anderen freigegebenen Ports sowie um andere **cloudverwaltete Dienste, die so konfiguriert werden k√∂nnen, dass sie freigegeben sind** (wie z. B. DBs oder Buckets)
  - Dann sollten Sie √ºberpr√ºfen, **ob diese Ressource freigegeben werden kann oder nicht** (vertrauliche Informationen? Schwachstellen? Fehlkonfigurationen im freigegebenen Dienst?)
- **Berechtigungen √ºberpr√ºfen**
  - Hier sollten Sie **alle Berechtigungen jedes Rollen/Benutzers** in der Cloud herausfinden und wie sie verwendet werden
  - Zu **viele stark privilegierte** (kontrollieren alles) Konten? Generierte Schl√ºssel nicht verwendet?... Die meisten dieser √úberpr√ºfungen sollten bereits in den Benchmark-Tests durchgef√ºhrt worden sein
  - Wenn der Kunde OpenID oder SAML oder andere **F√∂derationen** verwendet, m√ºssen Sie m√∂glicherweise weitere **Informationen** dar√ºber **anfordern, wie jede Rolle zugewiesen wird** (es ist nicht dasselbe, ob die Admin-Rolle einem Benutzer oder 100 Benutzern zugewiesen ist)
  - Es reicht **nicht aus zu finden**, welche Benutzer **Admin**-Berechtigungen haben "\*:\*". Es gibt viele **andere Berechtigungen**, die je nach den verwendeten Diensten sehr **sensibel** sein k√∂nnen.
  - Dar√ºber hinaus gibt es **potenzielle Privesc**-Wege, die missbr√§uchlich genutzt werden k√∂nnen. All diese Dinge sollten ber√ºcksichtigt werden, und es sollten **so viele Privesc-Pfade wie m√∂glich** gemeldet werden.
- **Integrationen √ºberpr√ºfen**
  - Es ist sehr wahrscheinlich, dass **Integrationen mit anderen Clouds oder SaaS** in der Cloud-Umgebung verwendet werden.
  - F√ºr **Integrationen der Cloud, die Sie √ºberpr√ºfen**, mit anderen Plattformen sollten Sie benachrichtigen, **wer Zugriff hat, um diese Integration zu (miss)brauchen**, und Sie sollten fragen, **wie sensibel** die durchgef√ºhrte Aktion ist.\
    Zum Beispiel, wer kann in einem AWS-Bucket schreiben, von dem GCP Daten bezieht (fragen Sie, wie sensibel die Aktion in GCP ist, wenn diese Daten behandelt werden).
  - F√ºr **Integrationen innerhalb der Cloud, die Sie √ºberpr√ºfen**, von externen Plattformen aus sollten Sie fragen, **wer externen Zugriff hat, um diese Integration zu (miss)brauchen**, und √ºberpr√ºfen, wie diese Daten verwendet werden.\
    Zum Beispiel, wenn ein Dienst ein in GCR gehostetes Docker-Image verwendet, sollten Sie herausfinden, wer Zugriff hat, um dies zu √§ndern, und welche sensiblen Informationen und Zugriffsberechtigungen dieses Image erh√§lt, wenn es in einer AWS-Cloud ausgef√ºhrt wird.

## Multi-Cloud-Tools

Es gibt mehrere Tools, die verwendet werden k√∂nnen, um verschiedene Cloud-Umgebungen zu testen. Die Installationsanleitungen und Links werden in diesem Abschnitt angegeben.

### [PurplePanda](https://github.com/carlospolop/purplepanda)

Ein Tool zur **Identifizierung von schlechten Konfigurationen und Privesc-Pfaden in Clouds und √ºber Clouds/SaaS hinweg.**

{% tabs %}
{% tab title="Installieren" %}
```bash
# You need to install and run neo4j also
git clone https://github.com/carlospolop/PurplePanda
cd PurplePanda
python3 -m venv .
source bin/activate
python3 -m pip install -r requirements.txt
export PURPLEPANDA_NEO4J_URL="bolt://neo4j@localhost:7687"
export PURPLEPANDA_PWD="neo4j_pwd_4_purplepanda"
python3 main.py -h # Get help
```
{% endtab %}

{% tab title="GCP" %} 

### Methodology

1. **Reconnaissance**: 
   - **Google Dorks**: Search for sensitive information exposed in Google.
   - **Subdomain Enumeration**: Enumerate subdomains using tools like Sublist3r, Subfinder, etc.
   - **DNS Enumeration**: Enumerate DNS records using tools like dig, nslookup, etc.
   - **Cloud Storage Enumeration**: Enumerate buckets and files in Google Cloud Storage using tools like GCSBucket, GCPBucketBrute, etc.

2. **Enumeration**:
   - **Service Enumeration**: Identify services running on the target.
   - **Port Scanning**: Scan open ports using tools like Nmap, Masscan, etc.
   - **Web Enumeration**: Enumerate web applications using tools like Dirb, Gobuster, etc.

3. **Vulnerability Assessment**:
   - **Vulnerability Scanning**: Scan for vulnerabilities using tools like Nessus, OpenVAS, etc.
   - **Web Application Scanning**: Scan web applications for vulnerabilities using tools like OWASP ZAP, Burp Suite, etc.

4. **Exploitation**:
   - **Exploit Research**: Search for known exploits related to the identified vulnerabilities.
   - **Manual Exploitation**: Exploit vulnerabilities manually if no automated exploit is available.

5. **Post-Exploitation**:
   - **Maintain Access**: Ensure persistent access to the target system.
   - **Privilege Escalation**: Elevate privileges on the target system.
   - **Data Exfiltration**: Extract sensitive data from the target system.

6. **Reporting**:
   - **Documentation**: Document all findings, exploits, and recommendations.
   - **Reporting**: Generate a detailed report for the client including the identified vulnerabilities and their impact.

{% endtab %}
```bash
export GOOGLE_DISCOVERY=$(echo 'google:
- file_path: ""

- file_path: ""
service_account_id: "some-sa-email@sidentifier.iam.gserviceaccount.com"' | base64)

python3 main.py -a -p google #Get basic info of the account to check it's correctly configured
python3 main.py -e -p google #Enumerate the env
```
{% endtab %}
{% endtabs %}

### [Prowler](https://github.com/prowler-cloud/prowler)

Es unterst√ºtzt **AWS, GCP & Azure**. √úberpr√ºfen Sie, wie Sie jeden Anbieter unter [https://docs.prowler.cloud/en/latest/#aws](https://docs.prowler.cloud/en/latest/#aws) konfigurieren k√∂nnen.
```bash
# Install
pip install prowler
prowler -v

# Run
prowler <provider>
# Example
prowler aws --profile custom-profile [-M csv json json-asff html]

# Get info about checks & services
prowler <provider> --list-checks
prowler <provider> --list-services
```
### [CloudSploit](https://github.com/aquasecurity/cloudsploit)

AWS, Azure, Github, Google, Oracle, Alibaba

{% tabs %}
{% tab title="Install" %}
```bash
# Install
git clone https://github.com/aquasecurity/cloudsploit.git
cd cloudsploit
npm install
./index.js -h
## Docker instructions in github
```
{% endtab %}

{% tab title="GCP" %}
```bash
## You need to have creds for a service account and set them in config.js file
./index.js --cloud google --config </abs/path/to/config.js>
```
{% endtab %}
{% endtabs %}

### [ScoutSuite](https://github.com/nccgroup/ScoutSuite)

AWS, Azure, GCP, Alibaba Cloud, Oracle Cloud Infrastructure

{% tabs %}
{% tab title="Install" %}
```bash
mkdir scout; cd scout
virtualenv -p python3 venv
source venv/bin/activate
pip install scoutsuite
scout --help
## Using Docker: https://github.com/nccgroup/ScoutSuite/wiki/Docker-Image
```
{% endtab %}

{% tab title="GCP" %} 

### Methodology

#### 1. **Reconnaissance**

   - **Google Dorks**: Use specific Google search queries to find sensitive information exposed on the internet.
   - **Subdomain Enumeration**: Enumerate subdomains using tools like Sublist3r, Subfinder, etc.
   - **DNS Enumeration**: Enumerate DNS records using tools like `dnsrecon`, `dnsenum`, etc.
   - **Cloud Storage Enumeration**: Identify publicly accessible cloud storage buckets using tools like `gcs-scanner`.
   - **GitHub Recon**: Search for sensitive information in GitHub repositories using tools like `truffleHog`, `gitrob`, etc.

#### 2. **Enumeration**

   - **Port Scanning**: Scan for open ports and services using tools like Nmap.
   - **Service Enumeration**: Enumerate services running on discovered ports using tools like `enum4linux`, `nmap`, etc.
   - **Web Enumeration**: Enumerate web applications for vulnerabilities using tools like `Gobuster`, `Dirb`, etc.

#### 3. **Vulnerability Assessment**

   - **Web Application Testing**: Test web applications for common vulnerabilities like SQL injection, XSS, etc.
   - **Cloud Service Misconfigurations**: Check for misconfigurations in cloud services that could lead to security issues.
   - **API Testing**: Test APIs for vulnerabilities like insecure API endpoints, lack of authentication, etc.

#### 4. **Exploitation**

   - **Exploit Development**: Develop and execute exploits for identified vulnerabilities.
   - **Post-Exploitation**: Maintain access and gather further information post exploitation.

#### 5. **Reporting**

   - **Documentation**: Document all findings, including vulnerabilities, exploited systems, and recommendations for mitigation.
   - **Executive Summary**: Provide a high-level summary of the assessment for stakeholders.

#### 6. **Post-Exploitation**

   - **Maintain Access**: Ensure continued access to compromised systems for further analysis.
   - **Cleanup**: Remove any traces of the attack to maintain stealth and avoid detection.

#### 7. **Pivoting**

   - **Lateral Movement**: Move laterally within the network to explore and compromise additional systems.
   - **Privilege Escalation**: Elevate privileges to gain higher access within the network.

#### 8. **Persistence**

   - **Establish Persistence**: Implement mechanisms to maintain access to compromised systems over time.
   - **Backdooring**: Install backdoors for future access to the system.

#### 9. **Covering Tracks**

   - **Log Cleaning**: Remove or modify logs to hide traces of unauthorized access.
   - **Artifact Removal**: Delete any artifacts or tools used during the assessment to avoid detection.

#### 10. **Social Engineering**

   - **Phishing**: Conduct phishing attacks to gather credentials or sensitive information.
   - **Human Interaction**: Exploit human vulnerabilities through social engineering techniques.

{% endtab %}
```bash
scout gcp --report-dir /tmp/gcp --user-account --all-projects
## use "--service-account KEY_FILE" instead of "--user-account" to use a service account

SCOUT_FOLDER_REPORT="/tmp"
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "================================================"
echo "Checking $pid"
mkdir "$SCOUT_FOLDER_REPORT/$pid"
scout gcp --report-dir "$SCOUT_FOLDER_REPORT/$pid" --no-browser --user-account --project-id "$pid"
done
```
{% endtab %}
{% endtabs %}

### [Steampipe](https://github.com/turbot)

{% tabs %}
{% tab title="Install" %}
Laden Sie Steampipe herunter und installieren Sie es ([https://steampipe.io/downloads](https://steampipe.io/downloads)). Oder verwenden Sie Brew:
```
brew tap turbot/tap
brew install steampipe
```
{% endtab %}

{% tab title="GCP" %} 

### Methodology

1. **Reconnaissance**: 
   - **Google Dorks**: Search for sensitive information exposed by Google.
   - **Subdomain Enumeration**: Enumerate subdomains to discover potential entry points.
   - **Cloud Storage Enumeration**: Identify publicly accessible storage buckets.
   - **GitHub Recon**: Search for leaked credentials or sensitive information on GitHub repositories.

2. **Enumeration**:
   - **Service Enumeration**: Identify services running on discovered hosts.
   - **Port Scanning**: Scan for open ports to identify potential attack vectors.
   - **Web Enumeration**: Enumerate web applications for vulnerabilities.

3. **Exploitation**:
   - **Weak Credentials**: Attempt to crack weak credentials or default passwords.
   - **Vulnerability Exploitation**: Exploit identified vulnerabilities to gain access.
   - **Data Exposure**: Look for sensitive data exposure through misconfigurations.

4. **Post-Exploitation**:
   - **Maintain Access**: Establish backdoors for persistent access.
   - **Privilege Escalation**: Elevate privileges to gain more control.
   - **Data Exfiltration**: Extract valuable data from the compromised system.

5. **Reporting**:
   - **Documentation**: Record findings, exploitation steps, and recommendations.
   - **Presentation**: Prepare a detailed report for the client including the impact of vulnerabilities and remediation steps.

{% endtab %}
```bash
# Install gcp plugin
steampipe plugin install gcp

# Use https://github.com/turbot/steampipe-mod-gcp-compliance.git
git clone https://github.com/turbot/steampipe-mod-gcp-compliance.git
cd steampipe-mod-gcp-compliance
# To run all the checks from the dashboard
steampipe dashboard
# To run all the checks from rhe cli
steampipe check all
```
<details>

<summary>√úberpr√ºfen Sie alle Projekte</summary>

Um alle Projekte zu √ºberpr√ºfen, m√ºssen Sie die Datei `gcp.spc` generieren, in der alle zu testenden Projekte angegeben sind. Sie k√∂nnen einfach den Anweisungen aus dem folgenden Skript folgen.
```bash
FILEPATH="/tmp/gcp.spc"
rm -rf "$FILEPATH" 2>/dev/null

# Generate a json like object for each project
for pid in $(gcloud projects list --format="value(projectId)"); do
echo "connection \"gcp_$(echo -n $pid | tr "-" "_" )\" {
plugin  = \"gcp\"
project = \"$pid\"
}" >> "$FILEPATH"
done

# Generate the aggragator to call
echo 'connection "gcp_all" {
plugin      = "gcp"
type        = "aggregator"
connections = ["gcp_*"]
}' >> "$FILEPATH"

echo "Copy $FILEPATH in ~/.steampipe/config/gcp.spc if it was correctly generated"
```
</details>

Um **andere GCP-Einblicke** zu √ºberpr√ºfen (n√ºtzlich zur Aufz√§hlung von Diensten) verwenden Sie: [https://github.com/turbot/steampipe-mod-gcp-insights](https://github.com/turbot/steampipe-mod-gcp-insights)

Um Terraform GCP-Code zu √ºberpr√ºfen: [https://github.com/turbot/steampipe-mod-terraform-gcp-compliance](https://github.com/turbot/steampipe-mod-terraform-gcp-compliance)

Weitere GCP-Plugins von Steampipe: [https://github.com/turbot?q=gcp](https://github.com/turbot?q=gcp)
{% endtab %}

{% tab title="AWS" %}
```bash
# Install aws plugin
steampipe plugin install aws

# Modify the spec indicating in "profile" the profile name to use
nano ~/.steampipe/config/aws.spc

# Get some info on how the AWS account is being used
git clone https://github.com/turbot/steampipe-mod-aws-insights.git
cd steampipe-mod-aws-insights
steampipe dashboard

# Get the services exposed to the internet
git clone https://github.com/turbot/steampipe-mod-aws-perimeter.git
cd steampipe-mod-aws-perimeter
steampipe dashboard

# Run the benchmarks
git clone https://github.com/turbot/steampipe-mod-aws-compliance
cd steampipe-mod-aws-compliance
steampipe dashboard # To see results in browser
steampipe check all --export=/tmp/output4.json
```
Um den Terraform AWS-Code zu √ºberpr√ºfen: [https://github.com/turbot/steampipe-mod-terraform-aws-compliance](https://github.com/turbot/steampipe-mod-terraform-aws-compliance)

Weitere AWS-Plugins von Steampipe: [https://github.com/orgs/turbot/repositories?q=aws](https://github.com/orgs/turbot/repositories?q=aws)
{% endtab %}
{% endtabs %}

### [~~cs-suite~~](https://github.com/SecurityFTW/cs-suite)

AWS, GCP, Azure, DigitalOcean.\
Es erfordert Python 2.7 und scheint nicht gewartet zu werden.

### Nessus

Nessus verf√ºgt √ºber einen _**Audit Cloud Infrastructure**_-Scan, der AWS, Azure, Office 365, Rackspace, Salesforce unterst√ºtzt. Einige zus√§tzliche Konfigurationen in **Azure** sind erforderlich, um eine **Client-ID** zu erhalten.

### [**cloudlist**](https://github.com/projectdiscovery/cloudlist)

Cloudlist ist ein **Multi-Cloud-Tool zum Abrufen von Assets** (Hostnamen, IP-Adressen) von Cloud-Anbietern.

{% tabs %}
{% tab title="Cloudlist" %}
```bash
cd /tmp
wget https://github.com/projectdiscovery/cloudlist/releases/latest/download/cloudlist_1.0.1_macOS_arm64.zip
unzip cloudlist_1.0.1_macOS_arm64.zip
chmod +x cloudlist
sudo mv cloudlist /usr/local/bin
```
{% endtab %}

{% tab title="Zweiter Tab" %}
```bash
## For GCP it requires service account JSON credentials
cloudlist -config </path/to/config>
```
{% endtab %}
{% endtabs %}

### [**Kartographie**](https://github.com/lyft/cartography)

Kartographie ist ein Python-Tool, das Infrastrukturressourcen und deren Beziehungen in einer intuitiven Grafikansicht zusammenfasst, die von einer Neo4j-Datenbank unterst√ºtzt wird.
```bash
# Installation
docker image pull ghcr.io/lyft/cartography
docker run --platform linux/amd64 ghcr.io/lyft/cartography cartography --help
## Install a Neo4j DB version 3.5.*
```
{% endtab %}

{% tab title="GCP" %} 

### Methodology

1. **Reconnaissance**: 
   - **Google Dorks**: Search for sensitive information exposed in Google.
   - **Subdomain Enumeration**: Enumerate subdomains using tools like Sublist3r, Subfinder, etc.
   - **Cloud Storage Enumeration**: Identify publicly accessible buckets using tools like GCPBucketBrute, GCPBucketDump, etc.
   - **GitHub Recon**: Look for sensitive information in GitHub repositories.

2. **Enumeration**:
   - **Service Enumeration**: Identify services running on the instances.
   - **Port Scanning**: Scan for open ports using tools like Nmap.
   - **Web Enumeration**: Enumerate web applications for vulnerabilities.

3. **Exploitation**:
   - **Weak Credentials**: Try default credentials or use brute force attacks.
   - **Vulnerability Exploitation**: Exploit identified vulnerabilities in services or applications.
   - **Data Exfiltration**: Extract sensitive data from the compromised system.

4. **Post-Exploitation**:
   - **Privilege Escalation**: Elevate privileges on the compromised system.
   - **Persistence**: Maintain access to the system for future attacks.
   - **Covering Tracks**: Remove evidence of the attack.

5. **Reporting**:
   - **Document Findings**: Record all findings, including vulnerabilities exploited and data accessed.
   - **Recommendations**: Provide recommendations for improving security based on the findings.

{% endtab %}
```bash
docker run --platform linux/amd64 \
--volume "$HOME/.config/gcloud/application_default_credentials.json:/application_default_credentials.json" \
-e GOOGLE_APPLICATION_CREDENTIALS="/application_default_credentials.json" \
-e NEO4j_PASSWORD="s3cr3t" \
ghcr.io/lyft/cartography  \
--neo4j-uri bolt://host.docker.internal:7687 \
--neo4j-password-env-var NEO4j_PASSWORD \
--neo4j-user neo4j


# It only checks for a few services inside GCP (https://lyft.github.io/cartography/modules/gcp/index.html)
## Cloud Resource Manager
## Compute
## DNS
## Storage
## Google Kubernetes Engine
### If you can run starbase or purplepanda you will get more info
```
{% endtab %}
{% endtabs %}

### [**starbase**](https://github.com/JupiterOne/starbase)

Starbase sammelt Assets und Beziehungen von Diensten und Systemen, einschlie√ülich Cloud-Infrastruktur, SaaS-Anwendungen, Sicherheitskontrollen und mehr, in einer intuitiven Grafikansicht, unterst√ºtzt von der Neo4j-Datenbank.
```bash
# You are going to need Node version 14, so install nvm following https://tecadmin.net/install-nvm-macos-with-homebrew/
npm install --global yarn
nvm install 14
git clone https://github.com/JupiterOne/starbase.git
cd starbase
nvm use 14
yarn install
yarn starbase --help
# Configure manually config.yaml depending on the env to analyze
yarn starbase setup
yarn starbase run

# Docker
git clone https://github.com/JupiterOne/starbase.git
cd starbase
cp config.yaml.example config.yaml
# Configure manually config.yaml depending on the env to analyze
docker build --no-cache -t starbase:latest .
docker-compose run starbase setup
docker-compose run starbase run
```
{% endtab %}

{% tab title="GCP" %} 

### Pentesting Cloud Methodology

#### 1. **Reconnaissance**

   - **Google Dorks**: Use advanced Google search operators to find sensitive information exposed on Google.
   - **Subdomain Enumeration**: Enumerate subdomains using tools like Sublist3r, Subfinder, or Amass.
   - **Cloud Storage Enumeration**: Identify publicly accessible cloud storage buckets using tools like GCPBucketBrute or GCPBucketDump.

#### 2. **Enumeration**

   - **Service Enumeration**: Identify services running on discovered hosts using tools like Nmap or Masscan.
   - **Port Scanning**: Scan for open ports on the target system using tools like Nmap or Masscan.
   - **Banner Grabbing**: Gather information about services running on open ports using tools like Netcat or Telnet.

#### 3. **Vulnerability Assessment**

   - **Vulnerability Scanning**: Scan for vulnerabilities on the target system using tools like Nessus, OpenVAS, or Nmap scripts.
   - **Web Application Testing**: Test web applications for common vulnerabilities like SQL injection, XSS, CSRF, etc.

#### 4. **Exploitation**

   - **Exploiting Misconfigurations**: Exploit misconfigured services or weak credentials to gain unauthorized access.
   - **Post-Exploitation**: Maintain access to the target system by deploying backdoors or creating new accounts.

#### 5. **Post-Exploitation**

   - **Privilege Escalation**: Elevate privileges on the target system to gain higher access levels.
   - **Pivoting**: Move laterally within the network by compromising additional hosts.

#### 6. **Reporting**

   - **Documentation**: Document all findings, including vulnerabilities discovered, exploited, and remediated.
   - **Recommendations**: Provide recommendations for improving the security posture of the target system.

#### 7. **Cleanup**

   - **Remove Traces**: Remove all traces of the pentest activities to maintain the target system's integrity and security.

{% endtab %}
```yaml
## Config for GCP
### Check out: https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md
### It requires service account credentials

integrations:
-
name: graph-google-cloud
instanceId: testInstanceId
directory: ./.integrations/graph-google-cloud
gitRemoteUrl: https://github.com/JupiterOne/graph-google-cloud.git
config:
SERVICE_ACCOUNT_KEY_FILE: '{Check https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md#service_account_key_file-string}'
PROJECT_ID: ""
FOLDER_ID: ""
ORGANIZATION_ID: ""
CONFIGURE_ORGANIZATION_PROJECTS: false

storage:
engine: neo4j
config:
username: neo4j
password: s3cr3t
uri: bolt://localhost:7687
#Consider using host.docker.internal if from docker
```
### [**SkyArk**](https://github.com/cyberark/SkyArk)

Entdecken Sie die privilegiertesten Benutzer in der gescannten AWS- oder Azure-Umgebung, einschlie√ülich der AWS Shadow Admins. Es verwendet PowerShell.
```powershell
Import-Module .\SkyArk.ps1 -force
Start-AzureStealth

# in the Cloud Console
IEX (New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/cyberark/SkyArk/master/AzureStealth/AzureStealth.ps1')
Scan-AzureAdmins
```
### [Cloud Brute](https://github.com/0xsha/CloudBrute)

Ein Tool, um die Infrastruktur, Dateien und Apps eines Unternehmens (Ziel) auf den f√ºhrenden Cloud-Anbietern (Amazon, Google, Microsoft, DigitalOcean, Alibaba, Vultr, Linode) zu finden.

### [CloudFox](https://github.com/BishopFox/cloudfox)

* CloudFox ist ein Tool, um ausnutzbare Angriffspfade in der Cloud-Infrastruktur zu finden (derzeit nur AWS & Azure unterst√ºtzt, mit GCP in K√ºrze).
* Es handelt sich um ein Aufz√§hlungstool, das dazu gedacht ist, manuelles Pentesting zu erg√§nzen.
* Es erstellt oder √§ndert keine Daten innerhalb der Cloud-Umgebung.

### Weitere Listen von Cloud-Sicherheitstools

* [https://github.com/RyanJarv/awesome-cloud-sec](https://github.com/RyanJarv/awesome-cloud-sec)

## Google

### GCP

{% content-ref url="gcp-security/" %}
[gcp-security](gcp-security/)
{% endcontent-ref %}

### Workspace

{% content-ref url="workspace-security/" %}
[workspace-security](workspace-security/)
{% endcontent-ref %}

## AWS

{% content-ref url="aws-security/" %}
[aws-security](aws-security/)
{% endcontent-ref %}

## Azure

{% content-ref url="azure-security/" %}
[azure-security](azure-security/)
{% endcontent-ref %}

### Angriffsgraph

[**Stormspotter** ](https://github.com/Azure/Stormspotter)erstellt einen "Angriffsgraphen" der Ressourcen in einem Azure-Abonnement. Es erm√∂glicht Red Teams und Pentestern, die Angriffsfl√§che und Pivot-M√∂glichkeiten innerhalb eines Mandanten zu visualisieren, und unterst√ºtzt Ihre Verteidiger dabei, sich schnell zu orientieren und die Incident-Response-Arbeit zu priorisieren.

### Office365

Sie ben√∂tigen **Global Admin** oder zumindest **Global Admin Reader** (aber beachten Sie, dass Global Admin Reader etwas eingeschr√§nkt ist). Diese Einschr√§nkungen treten jedoch in einigen PS-Modulen auf und k√∂nnen umgangen werden, indem Sie auf die Funktionen **√ºber die Webanwendung** zugreifen.
