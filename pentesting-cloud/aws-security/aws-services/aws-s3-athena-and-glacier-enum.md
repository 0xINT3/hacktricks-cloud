# AWS - S3, Athena & Glacier Enum

<details>

<summary><strong>Naucz się hakować AWS od zera do bohatera z</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (HackTricks AWS Red Team Expert)</strong></a><strong>!</strong></summary>

Inne sposoby wsparcia HackTricks:

* Jeśli chcesz zobaczyć swoją **firmę reklamowaną w HackTricks** lub **pobrać HackTricks w formacie PDF**, sprawdź [**SUBSCRIPTION PLANS**](https://github.com/sponsors/carlospolop)!
* Zdobądź [**oficjalne gadżety PEASS & HackTricks**](https://peass.creator-spring.com)
* Odkryj [**Rodzinę PEASS**](https://opensea.io/collection/the-peass-family), naszą kolekcję ekskluzywnych [**NFT**](https://opensea.io/collection/the-peass-family)
* **Dołącz do** 💬 [**grupy Discord**](https://discord.gg/hRep4RUj7f) lub [**grupy telegramowej**](https://t.me/peass) lub **śledź** nas na **Twitterze** 🐦 [**@hacktricks_live**](https://twitter.com/hacktricks_live)**.**
* **Podziel się swoimi sztuczkami hakerskimi, przesyłając PR-y do** [**HackTricks**](https://github.com/carlospolop/hacktricks) i [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github repos.

</details>

## S3

Amazon S3 to usługa, która umożliwia **przechowywanie dużych ilości danych**.

Amazon S3 zapewnia wiele opcji w celu **ochrony** danych w spoczynku. Opcje obejmują **Uprawnienia** (Polityka), **Szyfrowanie** (po stronie klienta i serwera), **Wersjonowanie kubełka** i **Usuwanie oparte na MFA**. **Użytkownik może włączyć** dowolną z tych opcji w celu ochrony danych. **Replikacja danych** to wewnętrzne narzędzie AWS, w którym **S3 automatycznie replikuje każdy obiekt we wszystkich strefach dostępności**, a organizacja nie musi go włączać w tym przypadku.

Z uprawnieniami opartymi na zasobach można definiować uprawnienia dla podkatalogów w kubełku oddzielnie.

### Wersjonowanie kubełka i usuwanie oparte na MFA

Po włączeniu wersjonowania kubełka, każda operacja, która próbuje zmienić plik wewnątrz pliku, spowoduje utworzenie nowej wersji pliku, zachowując również poprzednią zawartość tego samego pliku. W ten sposób nie zostanie nadpisana jego zawartość.

Co więcej, usuwanie oparte na MFA uniemożliwi usunięcie wersji pliku w kubełku S3 oraz wyłączenie wersjonowania kubełka, więc atakujący nie będzie mógł zmieniać tych plików.

### Dzienniki dostępu do S3

Możliwe jest **włączenie dzienników dostępu do S3** (które domyślnie są wyłączone) dla pewnego kubełka i zapisywanie dzienników w innym kubełku, aby dowiedzieć się, kto ma dostęp do kubełka (oba kubełki muszą znajdować się w tej samej regionie).

### Podpisane URL-e S3

Możliwe jest wygenerowanie podpisanego URL-a, który zazwyczaj można użyć do **uzyskania dostępu do określonego pliku** w kubełku. **Podpisany URL wygląda tak**:
```
https://<bucket-name>.s3.us-east-1.amazonaws.com/asd.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAUUE8GZC4S5L3TY3P%2F20230227%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230227T142551Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjELf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIBhQpdETJO3HKKDk2hjNIrPWwBE8gZaQccZFV3kCpPCWAiEAid3ueDtFFU%2FOQfUpvxYTGO%2BHoS4SWDMUrQAE0pIaB40qggMIYBAAGgwzMTgxNDIxMzg1NTMiDJLI5t7gr2EGxG1Y5CrfAioW0foHIQ074y4gvk0c%2B%2Fmqc7cNWb1njQslQkeePHkseJ3owzc%2FCwkgE0EuZTd4mw0aJciA2XIbJRCLPWTb%2FCBKPnIMJ5aBzIiA2ltsiUNQTTUxYmEgXZoJ6rFYgcodnmWW0Et4Xw59UlHnCDB2bLImxPprriyCzDDCD6nLyp3J8pFF1S8h3ZTJE7XguA8joMs4%2B2B1%2FeOZfuxXKyXPYSKQOOSbQiHUQc%2BFnOfwxleRL16prWk1t7TamvHR%2Bt3UgMn5QWzB3p8FgWwpJ6GjHLkYMJZ379tkimL1tJ7o%2BIod%2FMYrS7LDCifP9d%2FuYOhKWGhaakPuJKJh9fl%2B0vGl7kmApXigROxEWon6ms75laXebltsWwKcKuYca%2BUWu4jVJx%2BWUfI4ofoaGiCSaKALTqwu4QNBRT%2BMoK6h%2BQa7gN7JFGg322lkxRY53x27WMbUE4unn5EmI54T4dWt1%2Bg8ljDS%2BvKfBjqmAWRwuqyfwXa5YC3xxttOr3YVvR6%2BaXpzWtvNJQNnb6v0uI3%2BTtTexZkJpLQYqFcgZLQSxsXWSnf988qvASCIUhAzp2UnS1uqy7QjtD5T73zksYN2aesll7rvB80qIuujG6NOdHnRJ2M5%2FKXXNo1Yd15MtzPuSjRoSB9RSMon5jFu31OrQnA9eCUoawxbB0nHqwK8a43CKBZHhA8RoUAJW%2B48EuFsp3U%3D&X-Amz-Signature=3436e4139e84dbcf5e2e6086c0ebc92f4e1e9332b6fda24697bc339acbf2cdfa
```
Podpisany z góry URL można **utworzyć za pomocą wiersza poleceń przy użyciu poświadczeń podmiotu mającego dostęp do obiektu** (jeśli konto, którego używasz, nie ma dostępu, zostanie utworzony krótszy podpisany z góry URL, ale będzie bezużyteczny)
```bash
aws s3 presign --region <bucket-region> 's3://<bucket-name>/<file-name>'
```
{% hint style="info" %}
Jedynym wymaganym uprawnieniem do wygenerowania podpisanego adresu URL jest uprawnienie, które jest udzielane, więc dla poprzedniej komendy jedynym wymaganym uprawnieniem dla podmiotu jest `s3:GetObject`.
{% endhint %}

Możliwe jest również tworzenie podpisanych adresów URL z **innymi uprawnieniami**:
```python
import boto3
url = boto3.client('s3').generate_presigned_url(
ClientMethod='put_object',
Params={'Bucket': 'BUCKET_NAME', 'Key': 'OBJECT_KEY'},
ExpiresIn=3600
)
```
### Mechanizmy szyfrowania S3

**DEK oznacza klucz szyfrowania danych** i jest kluczem, który zawsze jest generowany i używany do szyfrowania danych.

<details>

<summary><strong>Szyfrowanie po stronie serwera przy użyciu zarządzanych kluczy S3, SSE-S3</strong></summary>

Ta opcja wymaga minimalnej konfiguracji, a zarządzanie kluczami szyfrowania jest obsługiwane przez AWS. Wszystko, co musisz zrobić, to **przesłać swoje dane, a S3 zajmie się resztą**. Każdemu kubełkowi w koncie S3 przypisywany jest klucz kubełka.

* Szyfrowanie:
* Dane obiektu + utworzony tekstowy DEK --> Zaszyfrowane dane (przechowywane wewnątrz S3)
* Utworzony tekstowy DEK + Klucz główny S3 --> Zaszyfrowany DEK (przechowywany wewnątrz S3), a tekstowy klucz jest usuwany z pamięci
* Deszyfrowanie:
* Zaszyfrowany DEK + Klucz główny S3 --> Tekstowy DEK
* Tekstowy DEK + Zaszyfrowane dane --> Dane obiektu

Należy zauważyć, że w tym przypadku **klucz jest zarządzany przez AWS** (rotacja co 3 lata). Jeśli używasz własnego klucza, będziesz mógł go rotować, wyłączać i stosować kontrolę dostępu.

</details>

<details>

<summary><strong>Szyfrowanie po stronie serwera przy użyciu zarządzanych kluczy KMS, SSE-KMS</strong></summary>

Ta metoda pozwala S3 na użycie usługi zarządzania kluczami do generowania kluczy szyfrowania danych. KMS daje większą elastyczność w zarządzaniu kluczami. Na przykład można wyłączać, rotować i stosować kontrolę dostępu do CMK oraz monitorować ich użycie za pomocą AWS Cloud Trail.

* Szyfrowanie:
* S3 żąda od KMS kluczy danych CMK
* KMS używa CMK do wygenerowania pary tekstowego DEK i zaszyfrowanego DEK, a następnie wysyła je do S3
* S3 używa klucza tekstowego do zaszyfrowania danych, przechowuje zaszyfrowane dane i zaszyfrowany klucz, a następnie usuwa klucz tekstowy z pamięci
* Deszyfrowanie:
* S3 prosi KMS o zdeszyfrowanie zaszyfrowanego klucza danych obiektu
* KMS deszyfruje klucz danych za pomocą CMK i odsyła go do S3
* S3 deszyfruje dane obiektu

</details>

<details>

<summary><strong>Szyfrowanie po stronie serwera przy użyciu kluczy dostarczonych przez klienta, SSE-C</strong></summary>

Ta opcja daje możliwość użycia własnego klucza głównego, który może być już używany poza AWS. Klucz dostarczony przez klienta jest następnie wysyłany wraz z danymi do S3, gdzie S3 wykonuje szyfrowanie.

* Szyfrowanie:
* Użytkownik wysyła dane obiektu + klucz klienta do S3
* Klucz klienta jest używany do zaszyfrowania danych, a zaszyfrowane dane są przechowywane
* zasolona wartość HMAC klucza klienta jest również przechowywana w celu przyszłej weryfikacji klucza
* klucz klienta jest usuwany z pamięci
* Deszyfrowanie:
* Użytkownik wysyła klucz klienta
* Klucz jest weryfikowany na podstawie przechowywanej wartości HMAC
* Dostarczony przez klienta klucz jest następnie używany do odszyfrowania danych

</details>

<details>

<summary><strong>Szyfrowanie po stronie klienta przy użyciu KMS, CSE-KMS</strong></summary>

Podobnie jak w przypadku SSE-KMS, ta metoda również wykorzystuje usługę zarządzania kluczami do generowania kluczy szyfrowania danych. Jednak tym razem KMS jest wywoływany przez klienta, a nie przez S3. Szyfrowanie odbywa się po stronie klienta, a zaszyfrowane dane są następnie wysyłane do S3 w celu przechowywania.

* Szyfrowanie:
* Klient żąda klucza danych od KMS
* KMS zwraca tekstowy DEK i zaszyfrowany DEK z CMK
* Oba klucze są wysyłane z powrotem
* Klient szyfruje dane za pomocą tekstowego DEK i wysyła do S3 zaszyfrowane dane + zaszyfrowany DEK (który jest zapisany jako metadane zaszyfrowanych danych wewnątrz S3)
* Deszyfrowanie:
* Zaszyfrowane dane wraz z zaszyfrowanym DEK są wysyłane do klienta
* Klient prosi KMS o zdeszyfrowanie zaszyfrowanego klucza za pomocą CMK, a KMS odsyła tekstowy DEK
* Klient może teraz odszyfrować zaszyfrowane dane

</details>

<details>

<summary><strong>Szyfrowanie po stronie klienta przy użyciu kluczy dostarczonych przez klienta, CSE-C</strong></summary>

Korzystając z tego mechanizmu, można użyć własnych kluczy i klienta AWS-SDK do zaszyfrowania danych przed ich wysłaniem do S3 w celu przechowywania.

* Szyfrowanie:
* Klient generuje DEK i szyfruje dane tekstowe
* Następnie, za pomocą własnego niestandardowego CMK, szyfruje DEK
* przesyła zaszyfrowane dane + zaszyfrowany DEK do S3, gdzie są przechowywane
* Deszyfrowanie:
* S3 wysyła zaszyfrowane dane i DEK
* Ponieważ klient już ma CMK używany do zaszyfrowania DEK, deszyfruje DEK, a następnie używa tekstowego DEK do odszyfrowania danych

</details>

### **Wyliczanie**

Jednym z tradycyjnych głównych sposobów kompromitacji organizacji AWS polega na kompromitacji publicznie dostępnych kubełków. **Możesz znaleźć** [**narzędzia do wyliczania publicznych kubełków na tej stronie**](../../aws-security/aws-unauthenticated-enum-access/#s3-buckets)**.**
```bash
# Get buckets ACLs
aws s3api get-bucket-acl --bucket <bucket-name>
aws s3api get-object-acl --bucket <bucket-name> --key flag

# Get policy
aws s3api get-bucket-policy --bucket <bucket-name>
aws s3api get-bucket-policy-status --bucket <bucket-name> #if it's public

# list S3 buckets associated with a profile
aws s3 ls
aws s3api list-buckets

# list content of bucket (no creds)
aws s3 ls s3://bucket-name --no-sign-request
aws s3 ls s3://bucket-name --recursive

# list content of bucket (with creds)
aws s3 ls s3://bucket-name
aws s3api list-objects-v2 --bucket <bucket-name>
aws s3api list-objects --bucket <bucket-name>
aws s3api list-object-versions --bucket <bucket-name>

# copy local folder to S3
aws s3 cp MyFolder s3://bucket-name --recursive

# delete
aws s3 rb s3://bucket-name –-force

# download a whole S3 bucket
aws s3 sync s3://<bucket>/ .

# move S3 bucket to different location
aws s3 sync s3://oldbucket s3://newbucket --source-region us-west-1

# list the sizes of an S3 bucket and its contents
aws s3api list-objects --bucket BUCKETNAME --output json --query "[sum(Contents[].Size), length(Contents[])]"

# Update Bucket policy
aws s3api put-bucket-policy --policy file:///root/policy.json --bucket <bucket-name>
##JSON policy example
{
"Id": "Policy1568185116930",
"Version": "2012-10-17",
"Statement": [
{
"Sid": "Stmt1568184932403",
"Action": [
"s3:ListBucket"
],
"Effect": "Allow",
"Resource": "arn:aws:s3:::welcome",
"Principal": "*"
},
{
"Sid": "Stmt1568185007451",
"Action": [
"s3:GetObject"
],
"Effect": "Allow",
"Resource": "arn:aws:s3:::welcome/*",
"Principal": "*"
}
]
}

# Update bucket ACL
aws s3api get-bucket-acl --bucket <bucket-name> # Way 1 to get the ACL
aws s3api put-bucket-acl --bucket <bucket-name> --access-control-policy file://acl.json

aws s3api get-object-acl --bucket <bucket-name> --key flag #Way 2 to get the ACL
aws s3api put-object-acl --bucket <bucket-name> --key flag --access-control-policy file://objacl.json

##JSON ACL example
## Make sure to modify the Owner’s displayName and ID according to the Object ACL you retrieved.
{
"Owner": {
"DisplayName": "<DisplayName>",
"ID": "<ID>"
},
"Grants": [
{
"Grantee": {
"Type": "Group",
"URI": "http://acs.amazonaws.com/groups/global/AuthenticatedUsers"
},
"Permission": "FULL_CONTROL"
}
]
}
## An ACL should give you the permission WRITE_ACP to be able to put a new ACL
```
### dual-stack <a href="#dual-stack-endpoints-description" id="dual-stack-endpoints-description"></a>

Możesz uzyskać dostęp do kubełka S3 za pomocą punktu końcowego dual-stack, używając nazwy punktu końcowego w stylu wirtualnym lub w stylu ścieżki. Są one przydatne do uzyskania dostępu do S3 za pośrednictwem IPv6.

Punkty końcowe dual-stack używają następującej składni:

* `bucketname.s3.dualstack.aws-region.amazonaws.com`
* `s3.dualstack.aws-region.amazonaws.com/bucketname`

### Przywileje podwyższania uprawnień

Na następnej stronie możesz sprawdzić, jak **wykorzystać uprawnienia S3 do podwyższenia uprawnień**:

{% content-ref url="../../aws-security/aws-privilege-escalation/aws-s3-privesc.md" %}
[aws-s3-privesc.md](../../aws-security/aws-privilege-escalation/aws-s3-privesc.md)
{% endcontent-ref %}

### Nieuwierzytelniony dostęp

{% content-ref url="../../aws-security/aws-unauthenticated-enum-access/aws-s3-unauthenticated-enum.md" %}
[aws-s3-unauthenticated-enum.md](../../aws-security/aws-unauthenticated-enum-access/aws-s3-unauthenticated-enum.md)
{% endcontent-ref %}

### Wykorzystanie po eksploatacji S3

{% content-ref url="../aws-post-exploitation/aws-s3-post-exploitation.md" %}
[aws-s3-post-exploitation.md](../aws-post-exploitation/aws-s3-post-exploitation.md)
{% endcontent-ref %}

### Trwałość

{% content-ref url="../aws-persistence/aws-s3-persistence.md" %}
[aws-s3-persistence.md](../aws-persistence/aws-s3-persistence.md)
{% endcontent-ref %}

## Inne podatności S3

### Problem z zatruciem pamięci podręcznej HTTP S3 <a href="#heading-s3-http-desync-cache-poisoning-issue" id="heading-s3-http-desync-cache-poisoning-issue"></a>

[Zgodnie z tym badaniem](https://rafa.hashnode.dev/exploiting-http-parsers-inconsistencies#heading-s3-http-desync-cache-poisoning-issue) możliwe było zapisanie odpowiedzi dowolnego kubełka w pamięci podręcznej, jakby należała do innego kubełka. Można było to wykorzystać do zmiany na przykład odpowiedzi plików JavaScript i kompromitacji dowolnych stron, które używają S3 do przechowywania kodu statycznego.

## Amazon Athena

Amazon Athena to interaktywna usługa zapytań, która ułatwia **analizowanie danych** bezpośrednio w usłudze Amazon Simple Storage Service (Amazon **S3**) **za pomocą** standardowego **SQL**.

Musisz **przygotować tabelę bazy danych relacyjnej** o formacie zawartości, która pojawi się w monitorowanych kubełkach S3. Następnie Amazon Athena będzie w stanie zapełnić bazę danych z logów, aby można było zapytać ją.

Amazon Athena obsługuje **możliwość zapytania danych S3, które są już zaszyfrowane**, a jeśli jest skonfigurowana w ten sposób, **Athena może również zaszyfrować wyniki zapytania, które można następnie przechowywać w S3**.

**Szyfrowanie wyników jest niezależne od zaszyfrowanych danych S3**, co oznacza, że nawet jeśli dane S3 nie są zaszyfrowane, wyniki zapytania mogą być zaszyfrowane. Kilka ważnych punktów, o których należy pamiętać, to fakt, że Amazon Athena obsługuje tylko dane, które zostały **zaszyfrowane** za pomocą **następujących metod szyfrowania S3**: **SSE-S3, SSE-KMS i CSE-KMS**.

Nie obsługiwane są SSE-C i CSE-E. Ponadto, ważne jest zrozumienie, że Amazon Athena będzie wykonywać zapytania tylko na **zaszyfrowanych obiektach, które znajdują się w tej samej regionie co samo zapytanie**. Jeśli chcesz zapytać dane S3, które zostały zaszyfrowane za pomocą KMS, wymagane są konkretne uprawnienia dla użytkownika Atheny, aby umożliwić mu wykonanie zapytania.

### Wyliczanie
```bash
# Get catalogs
aws athena list-data-catalogs

# Get databases inside catalog
aws athena list-databases --catalog-name <catalog-name>
aws athena list-table-metadata --catalog-name <catalog-name> --database-name <db-name>

# Get query executions, queries and results
aws athena list-query-executions
aws athena get-query-execution --query-execution-id <id> # Get query and meta of results
aws athena get-query-results --query-execution-id <id> # This will rerun the query and get the results

# Get workgroups & Prepared statements
aws athena list-work-groups
aws athena list-prepared-statements --work-group <wg-name>
aws athena get-prepared-statement --statement-name <name> --work-group <wg-name>

# Run query
aws athena start-query-execution --query-string <query>
```
## Odwołania

* [https://cloudsecdocs.com/aws/defensive/tooling/cli/#s3](https://cloudsecdocs.com/aws/defensive/tooling/cli/#s3)
* [https://docs.aws.amazon.com/AmazonS3/latest/userguide/dual-stack-endpoints.html](https://docs.aws.amazon.com/AmazonS3/latest/userguide/dual-stack-endpoints.html)

<details>

<summary><strong>Naucz się hakować AWS od zera do bohatera z</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (HackTricks AWS Red Team Expert)</strong></a><strong>!</strong></summary>

Inne sposoby wsparcia HackTricks:

* Jeśli chcesz zobaczyć swoją **firmę reklamowaną w HackTricks** lub **pobrać HackTricks w formacie PDF**, sprawdź [**PLAN SUBSKRYPCJI**](https://github.com/sponsors/carlospolop)!
* Zdobądź [**oficjalne gadżety PEASS & HackTricks**](https://peass.creator-spring.com)
* Odkryj [**Rodzinę PEASS**](https://opensea.io/collection/the-peass-family), naszą kolekcję ekskluzywnych [**NFT**](https://opensea.io/collection/the-peass-family)
* **Dołącz do** 💬 [**grupy Discord**](https://discord.gg/hRep4RUj7f) lub [**grupy telegramowej**](https://t.me/peass) lub **śledź** nas na **Twitterze** 🐦 [**@hacktricks_live**](https://twitter.com/hacktricks_live)**.**
* **Podziel się swoimi sztuczkami hakerskimi, przesyłając PR-y do** [**HackTricks**](https://github.com/carlospolop/hacktricks) i [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github repos.

</details>
