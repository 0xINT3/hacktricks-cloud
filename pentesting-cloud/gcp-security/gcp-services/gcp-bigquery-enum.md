# GCP - Enumerazione di Bigquery

<details>

<summary><strong>Impara l'hacking di AWS da zero a eroe con</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (HackTricks AWS Red Team Expert)</strong></a><strong>!</strong></summary>

Altri modi per supportare HackTricks:

* Se vuoi vedere la tua **azienda pubblicizzata su HackTricks** o **scaricare HackTricks in PDF** Controlla i [**PACCHETTI DI ABBONAMENTO**](https://github.com/sponsors/carlospolop)!
* Ottieni il [**merchandising ufficiale di PEASS & HackTricks**](https://peass.creator-spring.com)
* Scopri [**The PEASS Family**](https://opensea.io/collection/the-peass-family), la nostra collezione di [**NFT esclusivi**](https://opensea.io/collection/the-peass-family)
* **Unisciti al** üí¨ [**gruppo Discord**](https://discord.gg/hRep4RUj7f) o al [**gruppo Telegram**](https://t.me/peass) o **seguimi** su **Twitter** üê¶ [**@carlospolopm**](https://twitter.com/carlospolopm)**.**
* **Condividi i tuoi trucchi di hacking inviando PR a** [**HackTricks**](https://github.com/carlospolop/hacktricks) e [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud)
* &#x20;repository di GitHub.

</details>

## Informazioni di base

Google Cloud BigQuery √® descritto come un **data warehouse aziendale completamente gestito e serverless**, che offre funzionalit√† per l'**analisi di petabyte** di dati, gestendo quindi set di dati di grandi dimensioni in modo efficiente. Come Platform as a Service (PaaS), fornisce agli utenti infrastrutture e strumenti per facilitare la gestione dei dati senza la necessit√† di supervisione manuale.

### Crittografia

Per impostazione predefinita viene utilizzata una **chiave di crittografia gestita da Google**, anche se √® possibile configurare una **chiave di crittografia gestita dal cliente (CMEK)**. √à possibile indicare la chiave di crittografia per dataset e per tabella all'interno di un dataset.

### Scadenza

√à possibile indicare un **tempo di scadenza nel dataset**, in modo che ogni nuova tabella creata in questo dataset venga **automaticamente eliminata** il numero specificato di giorni dopo la creazione.

### Fonti esterne

Bigquery √® profondamente integrato con altri servizi di Google. √à possibile caricare dati da bucket, pub/sub, Google Drive, database RDS...

### ACL del dataset

Quando viene creato un dataset, vengono **allegate ACL** per concedere l'accesso ad esso. Per impostazione predefinita, vengono assegnati privilegi di **Proprietario** all'**utente che ha creato** il dataset, quindi **Proprietario** al gruppo **projectOwners** (Proprietari del progetto), **Scrittore** al gruppo **projectWriters** e **Lettore** al gruppo **projectReaders**:
```bash
bq show --format=prettyjson <proj>:<dataset>

...
"access": [
{
"role": "WRITER",
"specialGroup": "projectWriters"
},
{
"role": "OWNER",
"specialGroup": "projectOwners"
},
{
"role": "OWNER",
"userByEmail": "gcp-admin@hacktricks.xyz"
},
{
"role": "OWNER",
"userByEmail": "support@hacktricks.xyz"
},
{
"role": "READER",
"specialGroup": "projectReaders"
}
],
...
```
### Controllo dell'accesso alle righe della tabella

√à possibile **controllare le righe a cui un principale sar√† in grado di accedere all'interno di una tabella** con le politiche di accesso alle righe. Queste vengono definite all'interno della tabella utilizzando [**DDL**](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create\_row\_access\_policy\_statement).\
La politica di accesso definisce un filtro e solo le righe corrispondenti a tale filtro saranno **accessibili** dai principali indicati.
```sql
# Create
CREATE ROW ACCESS POLICY apac_filter
ON project.dataset.my_table
GRANT TO ('user:abc@example.com')
FILTER USING (region = 'APAC');

# Update
CREATE OR REPLACE ROW ACCESS POLICY
CREATE ROW ACCESS POLICY sales_us_filter
ON project.dataset.my_table
GRANT TO ('user:john@example.com',
'group:sales-us@example.com',
'group:sales-managers@example.com')
FILTER USING (region = 'US');

# Check the Post Exploitation tricks to see how to call this from the cli
```

```bash
# Enumerate row policies on a table
bq ls --row_access_policies <proj>:<dataset>.<table> # Get row policies
```
### Controllo degli accessi alle colonne

<figure><img src="../../../.gitbook/assets/image (3) (1).png" alt=""><figcaption></figcaption></figure>

Per limitare l'accesso ai dati a livello di colonna:

1. **Definire una tassonomia e tag di policy**. Crea e gestisci una tassonomia e tag di policy per i tuoi dati. [https://console.cloud.google.com/bigquery/policy-tags](https://console.cloud.google.com/bigquery/policy-tags)
2. Opzionale: Concedi il ruolo **Data Catalog Fine-Grained Reader a uno o pi√π principali** su uno o pi√π dei tag di policy creati.
3. **Assegna i tag di policy alle colonne di BigQuery**. In BigQuery, utilizza le annotazioni dello schema per assegnare un tag di policy a ciascuna colonna in cui desideri limitare l'accesso.
4. **Applica il controllo degli accessi sulla tassonomia**. L'applicazione del controllo degli accessi fa s√¨ che le restrizioni di accesso definite per tutti i tag di policy nella tassonomia vengano applicate.
5. **Gestisci l'accesso sui tag di policy**. Utilizza le [Identity and Access Management](https://cloud.google.com/iam) (IAM) policies per limitare l'accesso a ciascun tag di policy. La policy √® in vigore per ogni colonna che appartiene al tag di policy.

Quando un utente cerca di accedere ai dati di una colonna durante l'esecuzione di una query, BigQuery **controlla il tag di policy della colonna e la sua policy per verificare se l'utente √® autorizzato ad accedere ai dati**.

{% hint style="success" %}
In sintesi, per limitare l'accesso a determinate colonne per alcuni utenti, √® possibile **aggiungere un tag alla colonna nello schema e limitare l'accesso** degli utenti al tag applicando il controllo degli accessi sulla tassonomia del tag.
{% endhint %}

Per applicare il controllo degli accessi sulla tassonomia √® necessario abilitare il servizio:
```bash
gcloud services enable bigquerydatapolicy.googleapis.com
```
√à possibile visualizzare le etichette delle colonne con:

{% code overflow="wrap" %}
```bash
bq show --schema <proj>:<dataset>.<table>

[{"name":"username","type":"STRING","mode":"NULLABLE","policyTags":{"names":["projects/.../locations/us/taxonomies/2030629149897327804/policyTags/7703453142914142277"]},"maxLength":"20"},{"name":"age","type":"INTEGER","mode":"NULLABLE"}]
```
### Enumerazione

{% code overflow="wrap" %}
```bash
# Dataset info
bq ls # List datasets
bq ls -a # List all datasets (even hidden)
bq ls <proj>:<dataset> # List tables in a dataset
bq show --format=prettyjson <proj>:<dataset> # Get info about the dataset (like ACLs)

# Tables info
bq show --format=prettyjson <proj>:<dataset>.<table> # Get table info
bq show --schema <proj>:<dataset>.<table>  # Get schema of a table

# Get entries from the table
bq head <dataset>.<table>
bq query --nouse_legacy_sql 'SELECT * FROM `<proj>.<dataset>.<table-name>` LIMIT 1000'
bq extract <dataset>.<table> "gs://<bucket>/table*.csv" # Use the * so it can dump everything in different files

# Insert data
bq query --nouse_legacy_sql 'INSERT INTO `digital-bonfire-410512.importeddataset.tabletest` (rank, refresh_date, dma_name, dma_id, term, week, score) VALUES (22, "2023-12-28", "Baltimore MD", 512, "Ms", "2019-10-13", 62), (22, "2023-12-28", "Baltimore MD", 512, "Ms", "2020-05-24", 67)'
bq insert dataset.table /tmp/mydata.json

# Get permissions
bq get-iam-policy <proj>:<dataset> # Get dataset IAM policy
bq show --format=prettyjson <proj>:<dataset> # Get dataset ACLs
bq get-iam-policy <proj>:<dataset>.<table> # Get table IAM policy
bq ls --row_access_policies <proj>:<dataset>.<table> # Get row policies

# Taxonomies (Get the IDs from the shemas of the tables)
gcloud data-catalog taxonomies describe <taxonomi-ID> --location=<location>
gcloud data-catalog taxonomies list --location <location> #Find more
gcloud data-catalog taxonomies get-iam-policy <taxonomi-ID> --location=<location>

# Misc
bq show --encryption_service_account # Get encryption service account
```
{% endcode %}

### Iniezione SQL in BigQuery

[https://ozguralp.medium.com/bigquery-sql-injection-cheat-sheet-65ad70e11eac](https://ozguralp.medium.com/bigquery-sql-injection-cheat-sheet-65ad70e11eac)

### Escalatione dei privilegi e post-exploitation

{% content-ref url="../gcp-privilege-escalation/gcp-bigquery-privesc.md" %}
[gcp-bigquery-privesc.md](../gcp-privilege-escalation/gcp-bigquery-privesc.md)
{% endcontent-ref %}

### Persistenza

{% content-ref url="../gcp-persistence/gcp-bigquery-persistence.md" %}
[gcp-bigquery-persistence.md](../gcp-persistence/gcp-bigquery-persistence.md)
{% endcontent-ref %}

## Riferimenti

* [https://cloud.google.com/bigquery/docs/column-level-security-intro](https://cloud.google.com/bigquery/docs/column-level-security-intro)

<details>

<summary><strong>Impara l'hacking di AWS da zero a eroe con</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (HackTricks AWS Red Team Expert)</strong></a><strong>!</strong></summary>

Altri modi per supportare HackTricks:

* Se vuoi vedere la tua **azienda pubblicizzata in HackTricks** o **scaricare HackTricks in PDF** Controlla i [**PACCHETTI DI ABBONAMENTO**](https://github.com/sponsors/carlospolop)!
* Ottieni il [**merchandising ufficiale di PEASS & HackTricks**](https://peass.creator-spring.com)
* Scopri [**The PEASS Family**](https://opensea.io/collection/the-peass-family), la nostra collezione di esclusive [**NFT**](https://opensea.io/collection/the-peass-family)
* **Unisciti al** üí¨ [**gruppo Discord**](https://discord.gg/hRep4RUj7f) o al [**gruppo telegram**](https://t.me/peass) o **seguimi** su **Twitter** üê¶ [**@carlospolopm**](https://twitter.com/carlospolopm)**.**
* **Condividi i tuoi trucchi di hacking inviando PR a** [**HackTricks**](https://github.com/carlospolop/hacktricks) e [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud)
* &#x20;repository di github.

</details>
